{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79. Word Search\n",
    "127. Word Ladder\n",
    "126. Word Ladder II\n",
    "130. Surrounded Regions，被X包围的O改变成X，从边界出发，对边界能蔓延到的O不作处理，其余的全部更改\n",
    "199. Binary Tree Right Side View\n",
    "513. Find Bottom Left Tree Value\n",
    "515. Find Largest Value in Each Tree Row\n",
    "    [leaf for node in queue for leaf in (node.left,node.right) if leaf]\n",
    "    利用深度参数作DFS https://leetcode.com/problems/find-largest-value-in-each-tree-row/discuss/99018/Python-BFS-and-DFS\n",
    "200. Number of Islands，给定矩形往下遍历\n",
    "207. course schedule\n",
    "416. Partition Equal Subset Sum，将列表平分为两等分\n",
    "417. Pacific Atlantic Water Flow\n",
    "490. The Maze\n",
    "529. Minesweeper，给定矩形往下遍历\n",
    "542. 01 Matrix，给定矩形往下遍历\n",
    "695. Max Area of Island\n",
    "787. Cheapest Flights Within K Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200. Number of Islands\n",
    "# BFS和DFS界限并不明显\n",
    "# DFS: 找到一个满足的，用递归一直往下走，走的过程中完成操作\n",
    "# BFS：找到一个满足的，将下一步都存入队列，左边pop出\n",
    "def numIslands(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[List[str]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    if not grid: return 0\n",
    "    r, c = len(grid), len(grid[0])\n",
    "    visited = [[False for _ in range(c)] for _ in range(r)]\n",
    "\n",
    "    def dfs(i, j):\n",
    "        if i < 0 or i >= r or j < 0 or j >= c or grid[i][j] == '0' or visited[i][j]:\n",
    "            return\n",
    "        visited[i][j] = True\n",
    "        dfs(i + 1, j)\n",
    "        dfs(i - 1, j)\n",
    "        dfs(i, j + 1)\n",
    "        dfs(i, j - 1)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if not visited[i][j] and grid[i][j] == '1':\n",
    "                dfs(i, j)\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "numIslands([[\"1\",\"1\",\"1\",\"1\",\"0\"],[\"1\",\"1\",\"0\",\"1\",\"0\"],[\"1\",\"1\",\"0\",\"0\",\"0\"],[\"0\",\"0\",\"0\",\"0\",\"0\"]])\n",
    "\n",
    "# 694. Number of Distinct Islands，考虑形状\n",
    "import collections\n",
    "def numDistinctIslands(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[List[int]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    m,n=len(grid),len(grid[0])\n",
    "    directions = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "    islands = dict()#用一个字典来统计形状，value为相对值\n",
    "\n",
    "    def dfs(i,j):\n",
    "        visited[i][j]=True\n",
    "        queue = collections.deque([(i,j)])\n",
    "        curisland = {(i,j):set()}\n",
    "        while queue:\n",
    "            ii,jj = queue.popleft()\n",
    "            for dx,dy in directions:\n",
    "                x = ii+dx\n",
    "                y = jj+dy\n",
    "                if 0<=x<m and 0<=y<n and grid[x][y]==1 and visited[x][y] is False:\n",
    "                    visited[x][y] = True\n",
    "                    queue.append((x,y))\n",
    "                    curisland[(i,j)].add((x-i,y-j))\n",
    "        return isDistinct(curisland,i,j)\n",
    "\n",
    "    def isDistinct(curisland,i,j):\n",
    "        for island in islands:\n",
    "            if len(islands[island]) == len(curisland[(i,j)]) and islands[island] == curisland[(i,j)]:\n",
    "                return 0\n",
    "        islands[(i,j)] = curisland[(i,j)]\n",
    "        return 1\n",
    "\n",
    "    count = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if grid[i][j] and visited[i][j] is False:\n",
    "                count+=dfs(i,j)\n",
    "    return count\n",
    "numDistinctIslands([[1,1,0,1,1],[1,0,0,0,0],[0,0,0,0,1],[1,1,0,1,1]])\n",
    "\n",
    "# 711. Number of Distinct Islands II\n",
    "def numDistinctIslands2(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[List[int]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    m,n = len(grid),len(grid[0])\n",
    "    directions = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    islands = set()\n",
    "    visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "    def dfs(i,j):\n",
    "        visited[i][j] = True\n",
    "        stack = [(i,j)]\n",
    "        island = [(i,j)]\n",
    "        while stack:\n",
    "            i,j = stack.pop()\n",
    "            for dx,dy in directions:\n",
    "                x,y = i+dx,j+dy\n",
    "                if 0<=x<m and 0<=y<n and not visited[x][y] and grid[x][y]:\n",
    "                    island.append((x,y))\n",
    "                    stack.append((x,y))\n",
    "                    visited[x][y] = True\n",
    "        return isDistinct(island)\n",
    "        \n",
    "    def isDistinct(island):\n",
    "        island = sorted(island,key=lambda x:(x[0],x[1]))\n",
    "        island0 = getShape(island)\n",
    "        if island0 in islands:\n",
    "            return 0\n",
    "        islands.add(island0)\n",
    "\n",
    "        islands.add(getShape(sorted([(i,-j) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "        islands.add(getShape(sorted([(-i,-j) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "        islands.add(getShape(sorted([(-i,j) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "        islands.add(getShape(sorted([(j,i) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "        islands.add(getShape(sorted([(j,-i) for i,j in island], key=lambda x:(x[0],x[1]))))            \n",
    "        islands.add(getShape(sorted([(-j,i) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "        islands.add(getShape(sorted([(-j,-i) for i,j in island], key=lambda x:(x[0],x[1]))))\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def getShape(island):\n",
    "        return tuple((i-island[0][0],j-island[0][1]) for i,j in island)\n",
    "\n",
    "    res = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if not visited[i][j] and grid[i][j]:\n",
    "                res+=dfs(i,j)\n",
    "\n",
    "    return res               \n",
    "\n",
    "# 827. Making A Large Island，可以将其中的一个0换成1，求最大的岛屿\n",
    "# 先将所有的岛屿面积处理出来，然后对每个0的四周求和\n",
    "def largestIsland(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[List[int]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    if not grid or not grid[0]:\n",
    "        return 0\n",
    "    m,n = len(grid),len(grid[0])\n",
    "    visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "    counts = dict()\n",
    "    cur = 1\n",
    "\n",
    "    def dfs(i,j,cur):\n",
    "        level = [(i,j)]\n",
    "        visited[i][j]=True\n",
    "        area = 0\n",
    "        while level:\n",
    "            i,j = level.pop()\n",
    "            grid[i][j] = cur\n",
    "            area+=1\n",
    "            for dx,dy in [(-1,0),(1,0),(0,1),(0,-1)]:\n",
    "                x,y = i+dx,j+dy\n",
    "                if 0<=x<m and 0<=y<n and not visited[x][y] and grid[x][y]:\n",
    "                    visited[x][y]=True\n",
    "                    level.append((x,y))\n",
    "        counts[cur] = area\n",
    "        cur+=1\n",
    "        return cur\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if grid[i][j] and not visited[i][j]:\n",
    "                cur = dfs(i,j,cur)\n",
    "\n",
    "    maximum = 1\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if grid[i][j]==0:\n",
    "                temp = set()\n",
    "                for dx,dy in [(-1,0),(1,0),(0,1),(0,-1)]:\n",
    "                    x,y = i+dx,j+dy\n",
    "                    if 0<=x<m and 0<=y<n and grid[x][y]:\n",
    "                        temp.add(grid[x][y])\n",
    "                maximum = max(maximum,sum(counts[t] for t in temp)+1)\n",
    "    if not counts:\n",
    "        return 1\n",
    "    return max(maximum,max(counts.values()))\n",
    "\n",
    "largestIsland([[1, 1], [1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 959. Regions Cut By Slashes\n",
    "def regionsBySlashes(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[str]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    n = len(grid)\n",
    "    arr = [[0 for _ in range(3*n)] for _ in range(3*n)]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if grid[i][j]==\" \":\n",
    "                continue\n",
    "            elif grid[i][j] == \"/\":\n",
    "                arr[3*i][3*j+2]=1\n",
    "                arr[3*i+1][3*j+1]=1\n",
    "                arr[3*i+2][3*j] = 1\n",
    "            else:\n",
    "                arr[3*i][3*j],arr[3*i+1][3*j+1],arr[3*i+2][3*j+2]=[1,1,1]\n",
    "\n",
    "    visited = [[False for _ in range(3*n)] for _ in range(3*n)]\n",
    "\n",
    "    def dfs(i,j):\n",
    "        for dx,dy in [(-1,0),(1,0),(0,1),(0,-1)]:\n",
    "            x,y = i+dx,j+dy\n",
    "            if 0<=x<3*n and 0<=y<3*n and not visited[x][y] and arr[i][j]==0:\n",
    "                visited[x][y] = True\n",
    "                dfs(x,y)\n",
    "\n",
    "    res = 0\n",
    "    for i in range(3*n):\n",
    "        for j in range(3*n):\n",
    "            if not visited[i][j] and arr[i][j]==0:\n",
    "                visited[i][j] = True\n",
    "                res+=1\n",
    "                dfs(i,j)\n",
    "    return res\n",
    "regionsBySlashes([\"//\",\"/ \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 947. Most Stones Removed with Same Row or Column，同行或者同列可删除，最多多少个\n",
    "# 如果两个石头在同行或者同列，两个石头就是连接的。连在一起的石头，可以组成一个连通图。每一个连通图至少会剩下1个石头。\n",
    "import collections\n",
    "def removeStones(stones):\n",
    "    \"\"\"\n",
    "    :type stones: List[List[int]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    rows = collections.defaultdict(set)\n",
    "    cols = collections.defaultdict(set)\n",
    "    for i, j in stones:\n",
    "        rows[i].add(j)#第i行有哪些元素\n",
    "        cols[j].add(i)#第j行有哪些元素\n",
    "\n",
    "    def dfsRow(i):\n",
    "        seenR.add(i)\n",
    "        for j in rows[i]:\n",
    "            if j not in seenC:\n",
    "                dfsCol(j)\n",
    "\n",
    "    def dfsCol(j):\n",
    "        seenC.add(j)\n",
    "        for i in cols[j]:\n",
    "            if i not in seenR:\n",
    "                dfsRow(i)\n",
    "\n",
    "    seenR, seenC = set(), set()\n",
    "    islands = 0\n",
    "    for i, j in stones:\n",
    "        if i not in seenR:\n",
    "            islands += 1\n",
    "            dfsRow(i)\n",
    "            dfsCol(j)\n",
    "    return len(stones) - islands\n",
    "\n",
    "\n",
    "def removeStones(stones):\n",
    "    UF = {}\n",
    "    def find(x):\n",
    "        if x != UF[x]:\n",
    "            UF[x] = find(UF[x])\n",
    "        return UF[x]\n",
    "    def union(x, y):\n",
    "        UF.setdefault(x, x)\n",
    "        UF.setdefault(y, y)\n",
    "        UF[find(x)] = find(y)\n",
    "\n",
    "    for i, j in stones:\n",
    "        union(i, ~j)\n",
    "    return len(stones) - len({find(x) for x in UF})\n",
    "removeStones(stones = [[0,0],[0,1],[1,0],[1,2],[2,1],[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 542. 01 Matrix\n",
    "def updateMatrix(matrix):\n",
    "    q, m, n = [], len(matrix), len(matrix[0])\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if matrix[i][j] != 0:\n",
    "                matrix[i][j] = 0x7fffffff\n",
    "            else:\n",
    "                q.append((i, j))\n",
    "    for i, j in q:\n",
    "        for r, c in ((i, 1+j), (i, j-1), (i+1, j), (i-1, j)):\n",
    "            z = matrix[i][j] + 1\n",
    "            if 0 <= r < m and 0 <= c < n and matrix[r][c] > z:\n",
    "                matrix[r][c] = z\n",
    "                q.append((r, c))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 199. Binary Tree Right Side View\n",
    "#保存树每层最右一个元素\n",
    "# BFS: 层序遍历，用栈提取最后一个元素\n",
    "# DFS：从右到左深度优先，如果深度达到预定长度时有值，则保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 207. course schedule\n",
    "def canFinish(numCourses, prerequisites):\n",
    "    \"\"\"\n",
    "    :type numCourses: int\n",
    "    :type prerequisites: List[List[int]]\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    courses = {i for i in range(numCourses)}\n",
    "    while True:\n",
    "        if len(courses) == 0:\n",
    "            return True\n",
    "        cur = set()\n",
    "        for i in prerequisites:\n",
    "            cur.add(i[0])\n",
    "        completed,courses = courses - cur,cur\n",
    "        if len(completed)==0 and len(courses)!=0:\n",
    "            return False\n",
    "        prerequisites = [i for i in prerequisites if i[1] not in completed]\n",
    "# canFinish(6, [[1,3],[0,3],[3,4],[3,2],[4,2]] )\n",
    "canFinish(5,[[0,1],[2,1],[3,0],[2,0],[4,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward {0: {3}, 1: {3}, 2: set(), 3: {2, 4}, 4: {2}}\n",
      "backward defaultdict(<class 'set'>, {3: {0, 1}, 4: {3}, 2: {3, 4}, 0: set(), 1: set()})\n",
      "deque([0, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BFS,从后向前\n",
    "def canFinish1(numCourses, prerequisites):\n",
    "    forward = {i: set() for i in range(numCourses)}\n",
    "    backward = collections.defaultdict(set)\n",
    "    for i, j in prerequisites:\n",
    "        forward[i].add(j)\n",
    "        backward[j].add(i)\n",
    "    print('forward',forward)\n",
    "    print('backward',backward)\n",
    "    queue = collections.deque([node for node in forward if len(forward[node]) == 0])\n",
    "    print(queue)\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        for neigh in backward[node]:\n",
    "            forward[neigh].remove(node)\n",
    "            if len(forward[neigh]) == 0:\n",
    "                queue.append(neigh)\n",
    "        forward.pop(node)\n",
    "    return not forward  # if there is cycle, forward won't be None\n",
    "# BFS,从前向后\n",
    "def canFinish2(numCourses, prerequisites):\n",
    "    forward = {i: set() for i in range(numCourses)}\n",
    "    backward = collections.defaultdict(set)\n",
    "    for i, j in prerequisites:\n",
    "        forward[i].add(j)\n",
    "        backward[j].add(i)\n",
    "    queue = collections.deque([node for node in range(numCourses) if not backward[node]])\n",
    "    count = 0\n",
    "    print('forward',forward)\n",
    "    print('backward',backward)\n",
    "    print(queue)\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        count += 1\n",
    "        for neigh in forward[node]:# 对于有该先修课程的课程，去掉该边，如果这个节点无入度，则加入列表\n",
    "            backward[neigh].remove(node)\n",
    "            if not backward[neigh]:\n",
    "                queue.append(neigh)\n",
    "    return count == numCourses\n",
    "# DFS\n",
    "def canFinish(numCourses, prerequisites):\n",
    "    graph = [[] for _ in range(numCourses)]# 每个顶点的下家\n",
    "    visit = [0 for _ in range(numCourses)]\n",
    "    for x, y in prerequisites:\n",
    "        graph[x].append(y)\n",
    "    print(graph,visit)\n",
    "    def dfs(i):\n",
    "        if visit[i] == -1:#如果正在被访问，则返回False\n",
    "            return False\n",
    "        if visit[i] == 1:#如果被访问过，则返回True\n",
    "            return True\n",
    "        visit[i] = -1#正在被访问\n",
    "        for j in graph[i]:\n",
    "            if not dfs(j):\n",
    "                return False\n",
    "        visit[i] = 1\n",
    "        return True\n",
    "    for i in range(numCourses):\n",
    "        if not dfs(i):\n",
    "            return False\n",
    "    return True\n",
    "canFinish2(5, [[1,3],[0,3],[3,4],[3,2],[4,2]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上述拓扑排序的顺序，好像我弄反了\n",
    "def findOrder(numCourses, prerequisites):\n",
    "    forward = {i: set() for i in range(numCourses)}\n",
    "    backward = {i: set() for i in range(numCourses)}\n",
    "    for i, j in prerequisites:\n",
    "        forward[i].add(j)\n",
    "        backward[j].add(i)\n",
    "    queue = [i for i in backward if len(backward[i])==0]\n",
    "    res = []\n",
    "    counts = 0\n",
    "    print('forward',forward)\n",
    "    print('backward',backward)\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        res.append(node)\n",
    "        for i in forward[node]:\n",
    "            backward[i].remove(node)\n",
    "            if len(backward[i])==0:\n",
    "                queue.append(i)\n",
    "        counts+=1\n",
    "    if counts!=numCourses:\n",
    "        return []\n",
    "    return res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward {0: {5}, 1: {5}, 2: {3, 4}, 3: {0, 1}, 4: {3}, 5: set()}\n",
      "backward {0: {3}, 1: {3}, 2: set(), 3: {2, 4}, 4: {2}, 5: {0, 1}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 1, 0, 3, 4, 2]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findOrder(6,[[3,1],[3,0],[2,3],[4,3],[2,4],[1,5],[0,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 329. Longest Increasing Path in a Matrix\n",
    "# 关于需要类似迭代求解的，用DFS，用visit矩阵记录是否遍历过，思考DFS的过程中是否会找到终点\n",
    "def longestIncreasingPath(matrix):\n",
    "    if not matrix or not matrix[0]: return 0\n",
    "    m,n = len(matrix),len(matrix[0])\n",
    "    path = [[0 for i in range(n)] for _ in range(m)]\n",
    "    \n",
    "    def dfs(i,j):\n",
    "        if path[i][j]:\n",
    "            return path[i][j]\n",
    "        return max([dfs(i-1,j) if i>=1 and matrix[i][j]>matrix[i-1][j] else 0\\\n",
    "                   ,dfs(i+1,j) if i<m-1 and matrix[i][j]>matrix[i+1][j] else 0\\\n",
    "                   ,dfs(i,j-1) if j>=1 and matrix[i][j]>matrix[i][j-1] else 0\\\n",
    "                   ,dfs(i,j+1) if j<n-1 and matrix[i][j]>matrix[i][j+1] else 0])+1\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            path[i][j]=dfs(i,j)\n",
    "    return max([max(i) for i in path])\n",
    "matrix=[[0,1,2,3,4,5,6,7,8,9],[19,18,17,16,15,14,13,12,11,10],[20,21,22,23,24,25,26,27,28,29],[39,38,37,36,35,34,33,32,31,30],[40,41,42,43,44,45,46,47,48,49],[59,58,57,56,55,54,53,52,51,50],[60,61,62,63,64,65,66,67,68,69],[79,78,77,76,75,74,73,72,71,70],[80,81,82,83,84,85,86,87,88,89],[99,98,97,96,95,94,93,92,91,90],[100,101,102,103,104,105,106,107,108,109],[119,118,117,116,115,114,113,112,111,110],[120,121,122,123,124,125,126,127,128,129],[139,138,137,136,135,134,133,132,131,130],[0,0,0,0,0,0,0,0,0,0]]\n",
    "longestIncreasingPath(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B', 1, 'E', 'E', 'E'],\n",
       " ['B', 2, 'M', 'E', 'E'],\n",
       " ['B', 2, 'M', 'E', 'E'],\n",
       " ['B', 1, 'E', 'E', 'E']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 529. Minesweeper\n",
    "# 如果访问过，就不管；统计周围雷的个数，如果非0，则记为M，如果为0，则记为B，并且访问周围元素\n",
    "# 将要处理的节点存入栈后，DFS从后向前处理，BFS从前向后处理\n",
    "# https://leetcode.com/problems/minesweeper/discuss/144746/Python-BFS-%2B-DFS-with-comments\n",
    "def updateBoard(board, click):\n",
    "    \"\"\"\n",
    "    :type board: List[List[str]]\n",
    "    :type click: List[int]\n",
    "    :rtype: List[List[str]]\n",
    "    \"\"\"\n",
    "    m,n=len(board),len(board[0])\n",
    "    visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "    def update(i,j):\n",
    "        if visited[i][j]:\n",
    "            return board[i][j]\n",
    "        if board[i][j]=='M':\n",
    "            visited[i][j]=True\n",
    "            return 'X'\n",
    "        count = 0\n",
    "        for point in ([i-1,j-1],[i-1,j],[i-1,j+1],[i,j-1],[i,j],[i,j+1],[i+1,j-1],[i+1,j],[i+1,j+1]):\n",
    "            x,y = point[0],point[1]\n",
    "            if 0<=x<=m-1 and 0<=y<=n-1:\n",
    "                if board[x][y]=='M':\n",
    "                    count+=1\n",
    "        if count!=0:\n",
    "            visited[i][j]=True\n",
    "            return count\n",
    "        else:\n",
    "            visited[i][j]=True\n",
    "            for point in ([i-1,j-1],[i-1,j],[i-1,j+1],[i,j-1],[i,j],[i,j+1],[i+1,j-1],[i+1,j],[i+1,j+1]):\n",
    "                x,y = point[0],point[1]\n",
    "                if 0<=x<=m-1 and 0<=y<=n-1:\n",
    "                    board[x][y]=update(x,y)\n",
    "            return 'B'\n",
    "\n",
    "    board[click[0]][click[1]] = update(click[0],click[1])\n",
    "    return board\n",
    "\n",
    "board = [['E', 'E', 'E', 'E', 'E'],\n",
    " ['E', 'E', 'M', 'E', 'E'],\n",
    " ['E', 'E', 'M', 'E', 'E'],\n",
    " ['E', 'E', 'E', 'E', 'E']]\n",
    "updateBoard(board,[3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 130. Surrounded Regions\n",
    "# 从边界出发，如果为O，则继续往下走，或者可以将所有满足条件的存入队列然后BFS左边或DFS右边推出\n",
    "# 可以用栈队列求解DFS/BFS，可以用迭代求解\n",
    "def solve(board):#用迭代\n",
    "    \"\"\"\n",
    "    :type board: List[List[str]]\n",
    "    :rtype: None Do not return anything, modify board in-place instead.\n",
    "    \"\"\"\n",
    "    m,n = len(board),len(board[0])\n",
    "    visited = [[False for i in range(n)] for _ in range(m)]\n",
    "\n",
    "\n",
    "    def dfs(i,j):\n",
    "#         print(i,j,visited[i][j])\n",
    "        if not visited[i][j]:\n",
    "            if board[i][j]=='O':\n",
    "                visited[i][j]=True\n",
    "                for point in ([i-1,j],[i+1,j],[i,j-1],[i,j+1]):\n",
    "                    x,y = point[0],point[1]\n",
    "                    if 0<=x<m and 0<=y<n:\n",
    "                        dfs(x,y)\n",
    "    for i in [0,m-1]:\n",
    "        for j in range(n):\n",
    "            dfs(i,j)\n",
    "    for i in range(m):\n",
    "        for j in [0,n-1]:\n",
    "            dfs(i,j)\n",
    "\n",
    "    for i in range(1,m-1):\n",
    "        for j in range(1,n-1):\n",
    "            if board[i][j]=='O' and not visited[i][j]:\n",
    "                board[i][j]='X'\n",
    "    return board\n",
    "\n",
    "def solve(board):#用栈/队列\n",
    "    \"\"\"\n",
    "    :type board: List[List[str]]\n",
    "    :rtype: None Do not return anything, modify board in-place instead.\n",
    "    \"\"\"\n",
    "    m,n = len(board),len(board[0])\n",
    "    queue = collections.deque([])\n",
    "    for i in [0,m-1]:\n",
    "        for j in range(n):\n",
    "            if board[i][j]=='O':\n",
    "                queue.append((i,j))\n",
    "    for i in range(m):\n",
    "        for j in [0,n-1]:\n",
    "            if board[i][j]=='O':\n",
    "                queue.append((i,j))\n",
    "    \n",
    "    while queue:\n",
    "        x,y=queue.popleft()# BFS\n",
    "        if 0<=x<m and 0<=y<n and board[x][y]=='O':\n",
    "            queue.append((x-1,y));queue.append((x+1,y));queue.append((x,y-1));queue.append((x,y+1))\n",
    "            board[x][y]='D'\n",
    "#         x,y=queue.pop()#DFS\n",
    "#         if 0<=x<m and 0<=y<n and board[x][y]=='O':\n",
    "#             queue.append((x-1,y));queue.append((x+1,y));queue.append((x,y-1));queue.append((x,y+1))\n",
    "#             board[x][y]='D'\n",
    "            \n",
    "    for i in range(1,m):\n",
    "        for j in range(1,n):\n",
    "            if board[i][j]=='O':\n",
    "                board[i][j]='X'\n",
    "            if board[i][j]=='D':\n",
    "                board[i][j]='O'\n",
    "    return board\n",
    "\n",
    "solve([[\"X\",\"X\",\"X\",\"X\",\"X\"],[\"X\",\"O\",\"O\",\"O\",\"O\"],[\"X\",\"X\",\"O\",\"X\",\"X\"],[\"X\",\"O\",\"X\",\"X\",\"X\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 127. Word Ladder\n",
    "# 考虑到词库可能很长，要在原单词基础上人为修改，而不是在词库中每个单词比对，不同层次放在一起，为避免混淆，将每个元素添加一个元素表示层次\n",
    "def ladderLength(beginWord, endWord, wordList):\n",
    "    \"\"\"\n",
    "    :type beginWord: str\n",
    "    :type endWord: str\n",
    "    :type wordList: List[str]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    def match(s1, s2):\n",
    "        ok = False\n",
    "        for c1, c2 in zip(s1, s2):\n",
    "            if c1 != c2:\n",
    "                if ok:\n",
    "                    return False\n",
    "                else:\n",
    "                    ok = True\n",
    "        return ok\n",
    "    \n",
    "    wordList = set(wordList)\n",
    "    queue = {i for i in wordList if match(beginWord,i)}\n",
    "    prev = set()\n",
    "    res = 1\n",
    "    while queue:\n",
    "        newset = set()\n",
    "        res = res+1\n",
    "        for i in queue:\n",
    "            if i==endWord:\n",
    "                return res\n",
    "            for j in wordList:\n",
    "                if j not in queue and j not in prev and match(i,j):\n",
    "                    newset.add(j)\n",
    "        prev = prev|queue\n",
    "        queue = newset\n",
    "    return 0\n",
    "\n",
    "def ladderLength(beginWord, endWord, wordList):\n",
    "    wordList = set(wordList)\n",
    "    queue = collections.deque([[beginWord, 1]])\n",
    "    while queue:\n",
    "        word, length = queue.popleft()\n",
    "        if word == endWord:\n",
    "            return length\n",
    "        for i in range(len(word)):\n",
    "            for c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                next_word = word[:i] + c + word[i+1:]\n",
    "                if next_word in wordList:\n",
    "                    wordList.remove(next_word)\n",
    "                    queue.append([next_word, length + 1])\n",
    "    return 0\n",
    "\n",
    "wordList = [\"ricky\",\"grind\",\"cubic\",\"panic\",\"lover\",\"farce\",\"gofer\",\"sales\",\"flint\",\"omens\",\"lipid\",\"briny\",\"cloth\",\"anted\",\"slime\",\"oaten\",\"harsh\",\"touts\",\"stoop\",\"cabal\",\"lazed\",\"elton\",\"skunk\",\"nicer\",\"pesky\",\"kusch\",\"bused\",\"kinda\",\"tunis\",\"enjoy\",\"aches\",\"prowl\",\"babar\",\"rooms\",\"burst\",\"slush\",\"pines\",\"urine\",\"pinky\",\"bayed\",\"mania\",\"light\",\"flare\",\"wares\",\"women\",\"verne\",\"moron\",\"shine\",\"bluer\",\"zeros\",\"bleak\",\"brief\",\"tamra\",\"vasts\",\"jamie\",\"lairs\",\"penal\",\"worst\",\"yowls\",\"pills\",\"taros\",\"addle\",\"alyce\",\"creep\",\"saber\",\"floyd\",\"cures\",\"soggy\",\"vexed\",\"vilma\",\"cabby\",\"verde\",\"euler\",\"cling\",\"wanna\",\"jenny\",\"donor\",\"stole\",\"sakha\",\"blake\",\"sanes\",\"riffs\",\"forge\",\"horus\",\"sered\",\"piked\",\"prosy\",\"wases\",\"glove\",\"onset\",\"spake\",\"benin\",\"talks\",\"sites\",\"biers\",\"wendy\",\"dante\",\"allan\",\"haven\",\"nears\",\"shaka\",\"sloth\",\"perky\",\"spear\",\"spend\",\"clint\",\"dears\",\"sadly\",\"units\",\"vista\",\"hinds\",\"marat\",\"natal\",\"least\",\"bough\",\"pales\",\"boole\",\"ditch\",\"greys\",\"slunk\",\"bitch\",\"belts\",\"sense\",\"skits\",\"monty\",\"yawns\",\"music\",\"hails\",\"alien\",\"gibes\",\"lille\",\"spacy\",\"argot\",\"wasps\",\"drubs\",\"poops\",\"bella\",\"clone\",\"beast\",\"emend\",\"iring\",\"start\",\"darla\",\"bells\",\"cults\",\"dhaka\",\"sniff\",\"seers\",\"bantu\",\"pages\",\"fever\",\"tacky\",\"hoses\",\"strop\",\"climb\",\"pairs\",\"later\",\"grant\",\"raven\",\"stael\",\"drips\",\"lucid\",\"awing\",\"dines\",\"balms\",\"della\",\"galen\",\"toned\",\"snips\",\"shady\",\"chili\",\"fears\",\"nurse\",\"joint\",\"plump\",\"micky\",\"lions\",\"jamal\",\"queer\",\"ruins\",\"frats\",\"spoof\",\"semen\",\"pulps\",\"oldie\",\"coors\",\"rhone\",\"papal\",\"seals\",\"spans\",\"scaly\",\"sieve\",\"klaus\",\"drums\",\"tided\",\"needs\",\"rider\",\"lures\",\"treks\",\"hares\",\"liner\",\"hokey\",\"boots\",\"primp\",\"laval\",\"limes\",\"putts\",\"fonda\",\"damon\",\"pikes\",\"hobbs\",\"specs\",\"greet\",\"ketch\",\"braid\",\"purer\",\"tsars\",\"berne\",\"tarts\",\"clean\",\"grate\",\"trips\",\"chefs\",\"timex\",\"vicky\",\"pares\",\"price\",\"every\",\"beret\",\"vices\",\"jodie\",\"fanny\",\"mails\",\"built\",\"bossy\",\"farms\",\"pubic\",\"gongs\",\"magma\",\"quads\",\"shell\",\"jocks\",\"woods\",\"waded\",\"parka\",\"jells\",\"worse\",\"diner\",\"risks\",\"bliss\",\"bryan\",\"terse\",\"crier\",\"incur\",\"murky\",\"gamed\",\"edges\",\"keens\",\"bread\",\"raced\",\"vetch\",\"glint\",\"zions\",\"porno\",\"sizes\",\"mends\",\"ached\",\"allie\",\"bands\",\"plank\",\"forth\",\"fuels\",\"rhyme\",\"wimpy\",\"peels\",\"foggy\",\"wings\",\"frill\",\"edgar\",\"slave\",\"lotus\",\"point\",\"hints\",\"germs\",\"clung\",\"limed\",\"loafs\",\"realm\",\"myron\",\"loopy\",\"plush\",\"volts\",\"bimbo\",\"smash\",\"windy\",\"sours\",\"choke\",\"karin\",\"boast\",\"whirr\",\"tiber\",\"dimes\",\"basel\",\"cutes\",\"pinto\",\"troll\",\"thumb\",\"decor\",\"craft\",\"tared\",\"split\",\"josue\",\"tramp\",\"screw\",\"label\",\"lenny\",\"apses\",\"slept\",\"sikhs\",\"child\",\"bouts\",\"cites\",\"swipe\",\"lurks\",\"seeds\",\"fists\",\"hoard\",\"steed\",\"reams\",\"spoil\",\"diego\",\"peale\",\"bevel\",\"flags\",\"mazes\",\"quart\",\"snipe\",\"latch\",\"lards\",\"acted\",\"falls\",\"busby\",\"holed\",\"mummy\",\"wrong\",\"wipes\",\"carlo\",\"leers\",\"wails\",\"night\",\"pasty\",\"eater\",\"flunk\",\"vedas\",\"curse\",\"tyros\",\"mirth\",\"jacky\",\"butte\",\"wired\",\"fixes\",\"tares\",\"vague\",\"roved\",\"stove\",\"swoon\",\"scour\",\"coked\",\"marge\",\"cants\",\"comic\",\"corns\",\"zilch\",\"typos\",\"lives\",\"truer\",\"comma\",\"gaily\",\"teals\",\"witty\",\"hyper\",\"croat\",\"sways\",\"tills\",\"hones\",\"dowel\",\"llano\",\"clefs\",\"fores\",\"cinch\",\"brock\",\"vichy\",\"bleed\",\"nuder\",\"hoyle\",\"slams\",\"macro\",\"arabs\",\"tauts\",\"eager\",\"croak\",\"scoop\",\"crime\",\"lurch\",\"weals\",\"fates\",\"clipt\",\"teens\",\"bulls\",\"domed\",\"ghana\",\"culls\",\"frame\",\"hanky\",\"jared\",\"swain\",\"truss\",\"drank\",\"lobby\",\"lumps\",\"pansy\",\"whews\",\"saris\",\"trite\",\"weeps\",\"dozes\",\"jeans\",\"flood\",\"chimu\",\"foxes\",\"gelds\",\"sects\",\"scoff\",\"poses\",\"mares\",\"famed\",\"peers\",\"hells\",\"laked\",\"zests\",\"wring\",\"steal\",\"snoot\",\"yodel\",\"scamp\",\"ellis\",\"bandy\",\"marry\",\"jives\",\"vises\",\"blurb\",\"relay\",\"patch\",\"haley\",\"cubit\",\"heine\",\"place\",\"touch\",\"grain\",\"gerry\",\"badly\",\"hooke\",\"fuchs\",\"savor\",\"apron\",\"judge\",\"loren\",\"britt\",\"smith\",\"tammy\",\"altar\",\"duels\",\"huber\",\"baton\",\"dived\",\"apace\",\"sedan\",\"basts\",\"clark\",\"mired\",\"perch\",\"hulks\",\"jolly\",\"welts\",\"quack\",\"spore\",\"alums\",\"shave\",\"singe\",\"lanny\",\"dread\",\"profs\",\"skeet\",\"flout\",\"darin\",\"newed\",\"steer\",\"taine\",\"salvo\",\"mites\",\"rules\",\"crash\",\"thorn\",\"olive\",\"saves\",\"yawed\",\"pique\",\"salon\",\"ovens\",\"dusty\",\"janie\",\"elise\",\"carve\",\"winds\",\"abash\",\"cheep\",\"strap\",\"fared\",\"discs\",\"poxed\",\"hoots\",\"catch\",\"combo\",\"maize\",\"repay\",\"mario\",\"snuff\",\"delve\",\"cored\",\"bards\",\"sudan\",\"shuns\",\"yukon\",\"jowls\",\"wayne\",\"torus\",\"gales\",\"creek\",\"prove\",\"needy\",\"wisps\",\"terri\",\"ranks\",\"books\",\"dicky\",\"tapes\",\"aping\",\"padre\",\"roads\",\"nines\",\"seats\",\"flats\",\"rains\",\"moira\",\"basic\",\"loves\",\"pulls\",\"tough\",\"gills\",\"codes\",\"chest\",\"teeny\",\"jolts\",\"woody\",\"flame\",\"asked\",\"dulls\",\"hotly\",\"glare\",\"mucky\",\"spite\",\"flake\",\"vines\",\"lindy\",\"butts\",\"froth\",\"beeps\",\"sills\",\"bunny\",\"flied\",\"shaun\",\"mawed\",\"velds\",\"voled\",\"doily\",\"patel\",\"snake\",\"thigh\",\"adler\",\"calks\",\"desks\",\"janus\",\"spunk\",\"baled\",\"match\",\"strip\",\"hosed\",\"nippy\",\"wrest\",\"whams\",\"calfs\",\"sleet\",\"wives\",\"boars\",\"chain\",\"table\",\"duked\",\"riped\",\"edens\",\"galas\",\"huffs\",\"biddy\",\"claps\",\"aleut\",\"yucks\",\"bangs\",\"quids\",\"glenn\",\"evert\",\"drunk\",\"lusts\",\"senna\",\"slate\",\"manet\",\"roted\",\"sleep\",\"loxes\",\"fluky\",\"fence\",\"clamp\",\"doted\",\"broad\",\"sager\",\"spark\",\"belch\",\"mandy\",\"deana\",\"beyer\",\"hoist\",\"leafy\",\"levee\",\"libel\",\"tonic\",\"aloes\",\"steam\",\"skews\",\"tides\",\"stall\",\"rifts\",\"saxon\",\"mavis\",\"asama\",\"might\",\"dotes\",\"tangs\",\"wroth\",\"kited\",\"salad\",\"liens\",\"clink\",\"glows\",\"balky\",\"taffy\",\"sided\",\"sworn\",\"oasis\",\"tenth\",\"blurt\",\"tower\",\"often\",\"walsh\",\"sonny\",\"andes\",\"slump\",\"scans\",\"boded\",\"chive\",\"finer\",\"ponce\",\"prune\",\"sloes\",\"dined\",\"chums\",\"dingo\",\"harte\",\"ahead\",\"event\",\"freer\",\"heart\",\"fetch\",\"sated\",\"soapy\",\"skins\",\"royal\",\"cuter\",\"loire\",\"minot\",\"aisle\",\"horny\",\"slued\",\"panel\",\"eight\",\"snoop\",\"pries\",\"clive\",\"pored\",\"wrist\",\"piped\",\"daren\",\"cells\",\"parks\",\"slugs\",\"cubed\",\"highs\",\"booze\",\"weary\",\"stain\",\"hoped\",\"finny\",\"weeds\",\"fetid\",\"racer\",\"tasks\",\"right\",\"saint\",\"shahs\",\"basis\",\"refer\",\"chart\",\"seize\",\"lulls\",\"slant\",\"belay\",\"clots\",\"jinny\",\"tours\",\"modes\",\"gloat\",\"dunks\",\"flute\",\"conch\",\"marts\",\"aglow\",\"gayer\",\"lazes\",\"dicks\",\"chime\",\"bears\",\"sharp\",\"hatch\",\"forms\",\"terry\",\"gouda\",\"thins\",\"janet\",\"tonya\",\"axons\",\"sewed\",\"danny\",\"rowdy\",\"dolts\",\"hurry\",\"opine\",\"fifty\",\"noisy\",\"spiky\",\"humid\",\"verna\",\"poles\",\"jayne\",\"pecos\",\"hooky\",\"haney\",\"shams\",\"snots\",\"sally\",\"ruder\",\"tempe\",\"plunk\",\"shaft\",\"scows\",\"essie\",\"dated\",\"fleet\",\"spate\",\"bunin\",\"hikes\",\"sodas\",\"filly\",\"thyme\",\"fiefs\",\"perks\",\"chary\",\"kiths\",\"lidia\",\"lefty\",\"wolff\",\"withe\",\"three\",\"crawl\",\"wotan\",\"brown\",\"japed\",\"tolls\",\"taken\",\"threw\",\"crave\",\"clash\",\"layer\",\"tends\",\"notes\",\"fudge\",\"musky\",\"bawdy\",\"aline\",\"matts\",\"shirr\",\"balks\",\"stash\",\"wicks\",\"crepe\",\"foods\",\"fares\",\"rotes\",\"party\",\"petty\",\"press\",\"dolly\",\"mangy\",\"leeks\",\"silly\",\"leant\",\"nooks\",\"chapt\",\"loose\",\"caged\",\"wages\",\"grist\",\"alert\",\"sheri\",\"moody\",\"tamps\",\"hefts\",\"souls\",\"rubes\",\"rolex\",\"skulk\",\"veeps\",\"nonce\",\"state\",\"level\",\"whirl\",\"bight\",\"grits\",\"reset\",\"faked\",\"spiny\",\"mixes\",\"hunks\",\"major\",\"missy\",\"arius\",\"damns\",\"fitly\",\"caped\",\"mucus\",\"trace\",\"surat\",\"lloyd\",\"furry\",\"colin\",\"texts\",\"livia\",\"reply\",\"twill\",\"ships\",\"peons\",\"shear\",\"norms\",\"jumbo\",\"bring\",\"masks\",\"zippy\",\"brine\",\"dorks\",\"roded\",\"sinks\",\"river\",\"wolfs\",\"strew\",\"myths\",\"pulpy\",\"prank\",\"veins\",\"flues\",\"minus\",\"phone\",\"banns\",\"spell\",\"burro\",\"brags\",\"boyle\",\"lambs\",\"sides\",\"knees\",\"clews\",\"aired\",\"skirt\",\"heavy\",\"dimer\",\"bombs\",\"scums\",\"hayes\",\"chaps\",\"snugs\",\"dusky\",\"loxed\",\"ellen\",\"while\",\"swank\",\"track\",\"minim\",\"wiled\",\"hazed\",\"roofs\",\"cantu\",\"sorry\",\"roach\",\"loser\",\"brass\",\"stint\",\"jerks\",\"dirks\",\"emory\",\"campy\",\"poise\",\"sexed\",\"gamer\",\"catty\",\"comte\",\"bilbo\",\"fasts\",\"ledge\",\"drier\",\"idles\",\"doors\",\"waged\",\"rizal\",\"pured\",\"weirs\",\"crisp\",\"tasty\",\"sored\",\"palmy\",\"parts\",\"ethel\",\"unify\",\"crows\",\"crest\",\"udder\",\"delis\",\"punks\",\"dowse\",\"totes\",\"emile\",\"coded\",\"shops\",\"poppa\",\"pours\",\"gushy\",\"tiffs\",\"shads\",\"birds\",\"coils\",\"areas\",\"boons\",\"hulls\",\"alter\",\"lobes\",\"pleat\",\"depth\",\"fires\",\"pones\",\"serra\",\"sweat\",\"kline\",\"malay\",\"ruled\",\"calve\",\"tired\",\"drabs\",\"tubed\",\"wryer\",\"slung\",\"union\",\"sonya\",\"aided\",\"hewed\",\"dicey\",\"grids\",\"nixed\",\"whits\",\"mills\",\"buffs\",\"yucky\",\"drops\",\"ready\",\"yuppy\",\"tweet\",\"napes\",\"cadre\",\"teach\",\"rasps\",\"dowdy\",\"hoary\",\"canto\",\"posed\",\"dumbo\",\"kooks\",\"reese\",\"snaky\",\"binge\",\"byron\",\"phony\",\"safer\",\"friar\",\"novel\",\"scale\",\"huron\",\"adorn\",\"carla\",\"fauna\",\"myers\",\"hobby\",\"purse\",\"flesh\",\"smock\",\"along\",\"boils\",\"pails\",\"times\",\"panza\",\"lodge\",\"clubs\",\"colby\",\"great\",\"thing\",\"peaks\",\"diana\",\"vance\",\"whets\",\"bergs\",\"sling\",\"spade\",\"soaks\",\"beach\",\"traps\",\"aspen\",\"romps\",\"boxed\",\"fakir\",\"weave\",\"nerds\",\"swazi\",\"dotty\",\"curls\",\"diver\",\"jonas\",\"waite\",\"verbs\",\"yeast\",\"lapel\",\"barth\",\"soars\",\"hooks\",\"taxed\",\"slews\",\"gouge\",\"slags\",\"chang\",\"chafe\",\"saved\",\"josie\",\"syncs\",\"fonds\",\"anion\",\"actor\",\"seems\",\"pyrex\",\"isiah\",\"glued\",\"groin\",\"goren\",\"waxes\",\"tonia\",\"whine\",\"scads\",\"knelt\",\"teaks\",\"satan\",\"tromp\",\"spats\",\"merry\",\"wordy\",\"stake\",\"gland\",\"canal\",\"donna\",\"lends\",\"filed\",\"sacks\",\"shied\",\"moors\",\"paths\",\"older\",\"pooch\",\"balsa\",\"riced\",\"facet\",\"decaf\",\"attic\",\"elder\",\"akron\",\"chomp\",\"chump\",\"picky\",\"money\",\"sheer\",\"bolls\",\"crabs\",\"dorms\",\"water\",\"veers\",\"tease\",\"dummy\",\"dumbs\",\"lethe\",\"halls\",\"rifer\",\"demon\",\"fucks\",\"whips\",\"plops\",\"fuses\",\"focal\",\"taces\",\"snout\",\"edict\",\"flush\",\"burps\",\"dawes\",\"lorry\",\"spews\",\"sprat\",\"click\",\"deann\",\"sited\",\"aunts\",\"quips\",\"godly\",\"pupil\",\"nanny\",\"funks\",\"shoon\",\"aimed\",\"stacy\",\"helms\",\"mints\",\"banks\",\"pinch\",\"local\",\"twine\",\"pacts\",\"deers\",\"halos\",\"slink\",\"preys\",\"potty\",\"ruffs\",\"pusan\",\"suits\",\"finks\",\"slash\",\"prods\",\"dense\",\"edsel\",\"heeds\",\"palls\",\"slats\",\"snits\",\"mower\",\"rares\",\"ailed\",\"rouge\",\"ellie\",\"gated\",\"lyons\",\"duded\",\"links\",\"oaths\",\"letha\",\"kicks\",\"firms\",\"gravy\",\"month\",\"kongo\",\"mused\",\"ducal\",\"toted\",\"vocal\",\"disks\",\"spied\",\"studs\",\"macao\",\"erick\",\"coupe\",\"starr\",\"reaps\",\"decoy\",\"rayon\",\"nicks\",\"breed\",\"cosby\",\"haunt\",\"typed\",\"plain\",\"trays\",\"muled\",\"saith\",\"drano\",\"cower\",\"snows\",\"buses\",\"jewry\",\"argus\",\"doers\",\"flays\",\"swish\",\"resin\",\"boobs\",\"sicks\",\"spies\",\\\n",
    "            \"bails\",\"wowed\",\"mabel\",\"check\",\"vapid\",\"bacon\",\"wilda\",\"ollie\",\"loony\",\"irked\",\"fraud\",\"doles\",\"facts\",\"lists\",\"gazed\",\"furls\",\"sunks\",\"stows\",\"wilde\",\"brick\",\"bowed\",\"guise\",\"suing\",\"gates\",\"niter\",\"heros\",\"hyped\",\"clomp\",\"never\",\"lolls\",\"rangy\",\"paddy\",\"chant\",\"casts\",\"terns\",\"tunas\",\"poker\",\"scary\",\"maims\",\"saran\",\"devon\",\"tripe\",\"lingo\",\"paler\",\"coped\",\"bride\",\"voted\",\"dodge\",\"gross\",\"curds\",\"sames\",\"those\",\"tithe\",\"steep\",\"flaks\",\"close\",\"swops\",\"stare\",\"notch\",\"prays\",\"roles\",\"crush\",\"feuds\",\"nudge\",\"baned\",\"brake\",\"plans\",\"weepy\",\"dazed\",\"jenna\",\"weiss\",\"tomes\",\"stews\",\"whist\",\"gibed\",\"death\",\"clank\",\"cover\",\"peeks\",\"quick\",\"abler\",\"daddy\",\"calls\",\"scald\",\"lilia\",\"flask\",\"cheer\",\"grabs\",\"megan\",\"canes\",\"jules\",\"blots\",\"mossy\",\"begun\",\"freak\",\"caved\",\"hello\",\"hades\",\"theed\",\"wards\",\"darcy\",\"malta\",\"peter\",\"whorl\",\"break\",\"downs\",\"odder\",\"hoofs\",\"kiddo\",\"macho\",\"fords\",\"liked\",\"flees\",\"swing\",\"elect\",\"hoods\",\"pluck\",\"brook\",\"astir\",\"bland\",\"sward\",\"modal\",\"flown\",\"ahmad\",\"waled\",\"craps\",\"cools\",\"roods\",\"hided\",\"plath\",\"kings\",\"grips\",\"gives\",\"gnats\",\"tabby\",\"gauls\",\"think\",\"bully\",\"fogey\",\"sawed\",\"lints\",\"pushy\",\"banes\",\"drake\",\"trail\",\"moral\",\"daley\",\"balds\",\"chugs\",\"geeky\",\"darts\",\"soddy\",\"haves\",\"opens\",\"rends\",\"buggy\",\"moles\",\"freud\",\"gored\",\"shock\",\"angus\",\"puree\",\"raves\",\"johns\",\"armed\",\"packs\",\"minis\",\"reich\",\"slots\",\"totem\",\"clown\",\"popes\",\"brute\",\"hedge\",\"latin\",\"stoke\",\"blend\",\"pease\",\"rubik\",\"greer\",\"hindi\",\"betsy\",\"flows\",\"funky\",\"kelli\",\"humps\",\"chewy\",\"welds\",\"scowl\",\"yells\",\"cough\",\"sasha\",\"sheaf\",\"jokes\",\"coast\",\"words\",\"irate\",\"hales\",\"camry\",\"spits\",\"burma\",\"rhine\",\"bends\",\"spill\",\"stubs\",\"power\",\"voles\",\"learn\",\"knoll\",\"style\",\"twila\",\"drove\",\"dacca\",\"sheen\",\"papas\",\"shale\",\"jones\",\"duped\",\"tunny\",\"mouse\",\"floss\",\"corks\",\"skims\",\"swaps\",\"inned\",\"boxer\",\"synch\",\"skies\",\"strep\",\"bucks\",\"belau\",\"lower\",\"flaky\",\"quill\",\"aural\",\"rufus\",\"floes\",\"pokes\",\"sends\",\"sates\",\"dally\",\"boyer\",\"hurts\",\"foyer\",\"gowns\",\"torch\",\"luria\",\"fangs\",\"moats\",\"heinz\",\"bolts\",\"filet\",\"firth\",\"begot\",\"argue\",\"youth\",\"chimp\",\"frogs\",\"kraft\",\"smite\",\"loges\",\"loons\",\"spine\",\"domes\",\"pokey\",\"timur\",\"noddy\",\"doggy\",\"wades\",\"lanes\",\"hence\",\"louts\",\"turks\",\"lurid\",\"goths\",\"moist\",\"bated\",\"giles\",\"stood\",\"winos\",\"shins\",\"potts\",\"brant\",\"vised\",\"alice\",\"rosie\",\"dents\",\"babes\",\"softy\",\"decay\",\"meats\",\"tanya\",\"rusks\",\"pasts\",\"karat\",\"nuked\",\"gorge\",\"kinks\",\"skull\",\"noyce\",\"aimee\",\"watch\",\"cleat\",\"stuck\",\"china\",\"testy\",\"doses\",\"safes\",\"stage\",\"bayes\",\"twins\",\"limps\",\"denis\",\"chars\",\"flaps\",\"paces\",\"abase\",\"grays\",\"deans\",\"maria\",\"asset\",\"smuts\",\"serbs\",\"whigs\",\"vases\",\"robyn\",\"girls\",\"pents\",\"alike\",\"nodal\",\"molly\",\"swigs\",\"swill\",\"slums\",\"rajah\",\"bleep\",\"beget\",\"thanh\",\"finns\",\"clock\",\"wafts\",\"wafer\",\"spicy\",\"sorer\",\"reach\",\"beats\",\"baker\",\"crown\",\"drugs\",\"daisy\",\"mocks\",\"scots\",\"fests\",\"newer\",\"agate\",\"drift\",\"marta\",\"chino\",\"flirt\",\"homed\",\"bribe\",\"scram\",\"bulks\",\"servo\",\"vesta\",\"divas\",\"preps\",\"naval\",\"tally\",\"shove\",\"ragas\",\"blown\",\"droll\",\"tryst\",\"lucky\",\"leech\",\"lines\",\"sires\",\"pyxed\",\"taper\",\"trump\",\"payee\",\"midge\",\"paris\",\"bored\",\"loads\",\"shuts\",\"lived\",\"swath\",\"snare\",\"boned\",\"scars\",\"aeons\",\"grime\",\"writs\",\"paige\",\"rungs\",\"blent\",\"signs\",\"davis\",\"dials\",\"daubs\",\"rainy\",\"fawns\",\"wrier\",\"golds\",\"wrath\",\"ducks\",\"allow\",\"hosea\",\"spike\",\"meals\",\"haber\",\"muses\",\"timed\",\"broom\",\"burks\",\"louis\",\"gangs\",\"pools\",\"vales\",\"altai\",\"elope\",\"plied\",\"slain\",\"chasm\",\"entry\",\"slide\",\"bawls\",\"title\",\"sings\",\"grief\",\"viola\",\"doyle\",\"peach\",\"davit\",\"bench\",\"devil\",\"latex\",\"miles\",\"pasha\",\"tokes\",\"coves\",\"wheel\",\"tried\",\"verdi\",\"wanda\",\"sivan\",\"prior\",\"fryer\",\"plots\",\"kicky\",\"porch\",\"shill\",\"coats\",\"borne\",\"brink\",\"pawed\",\"erwin\",\"tense\",\"stirs\",\"wends\",\"waxen\",\"carts\",\"smear\",\"rival\",\"scare\",\"phase\",\"bragg\",\"crane\",\"hocks\",\"conan\",\"bests\",\"dares\",\"molls\",\"roots\",\"dunes\",\"slips\",\"waked\",\"fours\",\"bolds\",\"slosh\",\"yemen\",\"poole\",\"solid\",\"ports\",\"fades\",\"legal\",\"cedes\",\"green\",\"curie\",\"seedy\",\"riper\",\"poled\",\"glade\",\"hosts\",\"tools\",\"razes\",\"tarry\",\"muddy\",\"shims\",\"sword\",\"thine\",\"lasts\",\"bloat\",\"soled\",\"tardy\",\"foots\",\"skiff\",\"volta\",\"murks\",\"croci\",\"gooks\",\"gamey\",\"pyxes\",\"poems\",\"kayla\",\"larva\",\"slaps\",\"abuse\",\"pings\",\"plows\",\"geese\",\"minks\",\"derby\",\"super\",\"inked\",\"manic\",\"leaks\",\"flops\",\"lajos\",\"fuzes\",\"swabs\",\"twigs\",\"gummy\",\"pyres\",\"shrew\",\"islet\",\"doled\",\"wooly\",\"lefts\",\"hunts\",\"toast\",\"faith\",\"macaw\",\"sonia\",\"leafs\",\"colas\",\"conks\",\"altos\",\"wiped\",\"scene\",\"boors\",\"patsy\",\"meany\",\"chung\",\"wakes\",\"clear\",\"ropes\",\"tahoe\",\"zones\",\"crate\",\"tombs\",\"nouns\",\"garth\",\"puked\",\"chats\",\"hanks\",\"baked\",\"binds\",\"fully\",\"soaps\",\"newel\",\"yarns\",\"puers\",\"carps\",\"spelt\",\"lully\",\"towed\",\"scabs\",\"prime\",\"blest\",\"patty\",\"silky\",\"abner\",\"temps\",\"lakes\",\"tests\",\"alias\",\"mines\",\"chips\",\"funds\",\"caret\",\"splat\",\"perry\",\"turds\",\"junks\",\"cramp\",\"saned\",\"peary\",\"snarl\",\"fired\",\"stung\",\"nancy\",\"bulge\",\"styli\",\"seams\",\"hived\",\"feast\",\"triad\",\"jaded\",\"elvin\",\"canny\",\"birth\",\"routs\",\"rimed\",\"pusey\",\"laces\",\"taste\",\"basie\",\"malls\",\"shout\",\"prier\",\"prone\",\"finis\",\"claus\",\"loops\",\"heron\",\"frump\",\"spare\",\"menus\",\"ariel\",\"crams\",\"bloom\",\"foxed\",\"moons\",\"mince\",\"mixed\",\"piers\",\"deres\",\"tempt\",\"dryer\",\"atone\",\"heats\",\"dario\",\"hawed\",\"swims\",\"sheet\",\"tasha\",\"dings\",\"clare\",\"aging\",\"daffy\",\"wried\",\"foals\",\"lunar\",\"havel\",\"irony\",\"ronny\",\"naves\",\"selma\",\"gurus\",\"crust\",\"percy\",\"murat\",\"mauro\",\"cowed\",\"clang\",\"biker\",\"harms\",\"barry\",\"thump\",\"crude\",\"ulnae\",\"thong\",\"pager\",\"oases\",\"mered\",\"locke\",\"merle\",\"soave\",\"petal\",\"poser\",\"store\",\"winch\",\"wedge\",\"inlet\",\"nerdy\",\"utter\",\"filth\",\"spray\",\"drape\",\"pukes\",\"ewers\",\"kinds\",\"dates\",\"meier\",\"tammi\",\"spoor\",\"curly\",\"chill\",\"loped\",\"gooey\",\"boles\",\"genet\",\"boost\",\"beets\",\"heath\",\"feeds\",\"growl\",\"livid\",\"midst\",\"rinds\",\"fresh\",\"waxed\",\"yearn\",\"keeps\",\"rimes\",\"naked\",\"flick\",\"plies\",\"deeps\",\"dirty\",\"hefty\",\"messy\",\"hairy\",\"walks\",\"leper\",\"sykes\",\"nerve\",\"rover\",\"jived\",\"brisk\",\"lenin\",\"viper\",\"chuck\",\"sinus\",\"luger\",\"ricks\",\"hying\",\"rusty\",\"kathy\",\"herds\",\"wider\",\"getty\",\"roman\",\"sandy\",\"pends\",\"fezes\",\"trios\",\"bites\",\"pants\",\"bless\",\"diced\",\"earth\",\"shack\",\"hinge\",\"melds\",\"jonah\",\"chose\",\"liver\",\"salts\",\"ratty\",\"ashed\",\"wacky\",\"yokes\",\"wanly\",\"bruce\",\"vowel\",\"black\",\"grail\",\"lungs\",\"arise\",\"gluts\",\"gluey\",\"navel\",\"coyer\",\"ramps\",\"miter\",\"aldan\",\"booth\",\"musty\",\"rills\",\"darns\",\"tined\",\"straw\",\"kerri\",\"hared\",\"lucks\",\"metes\",\"penny\",\"radon\",\"palms\",\"deeds\",\"earls\",\"shard\",\"pried\",\"tampa\",\"blank\",\"gybes\",\"vicki\",\"drool\",\"groom\",\"curer\",\"cubes\",\"riggs\",\"lanky\",\"tuber\",\"caves\",\"acing\",\"golly\",\"hodge\",\"beard\",\"ginny\",\"jibed\",\"fumes\",\"astor\",\"quito\",\"cargo\",\"randi\",\"gawky\",\"zings\",\"blind\",\"dhoti\",\"sneak\",\"fatah\",\"fixer\",\"lapps\",\"cline\",\"grimm\",\"fakes\",\"maine\",\"erika\",\"dealt\",\"mitch\",\"olden\",\"joist\",\"gents\",\"likes\",\"shelf\",\"silts\",\"goats\",\"leads\",\"marin\",\"spire\",\"louie\",\"evans\",\"amuse\",\"belly\",\"nails\",\"snead\",\"model\",\"whats\",\"shari\",\"quote\",\"tacks\",\"nutty\",\"lames\",\"caste\",\"hexes\",\"cooks\",\"miner\",\"shawn\",\"anise\",\"drama\",\"trike\",\"prate\",\"ayers\",\"loans\",\"botch\",\"vests\",\"cilia\",\"ridge\",\"thugs\",\"outed\",\"jails\",\"moped\",\"plead\",\"tunes\",\"nosed\",\"wills\",\"lager\",\"lacks\",\"cried\",\"wince\",\"berle\",\"flaws\",\"boise\",\"tibet\",\"bided\",\"shred\",\"cocky\",\"brice\",\"delta\",\"congo\",\"holly\",\"hicks\",\"wraps\",\"cocks\",\"aisha\",\"heard\",\"cured\",\"sades\",\"horsy\",\"umped\",\"trice\",\"dorky\",\"curve\",\"ferry\",\"haler\",\"ninth\",\"pasta\",\"jason\",\"honer\",\"kevin\",\"males\",\"fowls\",\"awake\",\"pores\",\"meter\",\"skate\",\"drink\",\"pussy\",\"soups\",\"bases\",\"noyes\",\"torts\",\"bogus\",\"still\",\"soupy\",\"dance\",\"worry\",\"eldon\",\"stern\",\"menes\",\"dolls\",\"dumpy\",\"gaunt\",\"grove\",\"coops\",\"mules\",\"berry\",\"sower\",\"roams\",\"brawl\",\"greed\",\"stags\",\"blurs\",\"swift\",\"treed\",\"taney\",\"shame\",\"easel\",\"moves\",\"leger\",\"ville\",\"order\",\"spock\",\"nifty\",\"brian\",\"elias\",\"idler\",\"serve\",\"ashen\",\"bizet\",\"gilts\",\"spook\",\"eaten\",\"pumas\",\"cotes\",\"broke\",\"toxin\",\"groan\",\"laths\",\"joins\",\"spots\",\"hated\",\"tokay\",\"elite\",\"rawer\",\"fiats\",\"cards\",\"sassy\",\"milks\",\"roost\",\"glean\",\"lutes\",\"chins\",\"drown\",\"marks\",\"pined\",\"grace\",\"fifth\",\"lodes\",\"rusts\",\"terms\",\"maxes\",\"savvy\",\"choir\",\"savoy\",\"spoon\",\"halve\",\"chord\",\"hulas\",\"sarah\",\"celia\",\"deems\",\"ninny\",\"wines\",\"boggy\",\"birch\",\"raved\",\"wales\",\"beams\",\"vibes\",\"riots\",\"warty\",\"nigel\",\"askew\",\"faxes\",\"sedge\",\"sheol\",\"pucks\",\"cynic\",\"relax\",\"boers\",\"whims\",\"bents\",\"candy\",\"luann\",\"slogs\",\"bonny\",\"barns\",\"iambs\",\"fused\",\"duffy\",\"guilt\",\"bruin\",\"pawls\",\"penis\",\"poppy\",\"owing\",\"tribe\",\"tuner\",\"moray\",\"timid\",\"ceded\",\"geeks\",\"kites\",\"curio\",\"puffy\",\"perot\",\"caddy\",\"peeve\",\"cause\",\"dills\",\"gavel\",\"manse\",\"joker\",\"lynch\",\"crank\",\"golda\",\"waits\",\"wises\",\"hasty\",\"paves\",\"grown\",\"reedy\",\"crypt\",\"tonne\",\"jerky\",\"axing\",\"swept\",\"posse\",\"rings\",\"staff\",\"tansy\",\"pared\",\"glaze\",\"grebe\",\"gonna\",\"shark\",\"jumps\",\"vials\",\"unset\",\"hires\",\"tying\",\"lured\",\"motes\",\"linen\",\"locks\",\"mamas\",\"nasty\",\"mamie\",\"clout\",\"nader\",\"velma\",\"abate\",\"tight\",\"dales\",\"serer\",\"rives\",\"bales\",\"loamy\",\"warps\",\"plato\",\"hooch\",\"togae\",\"damps\",\"ofter\",\"plumb\",\"fifes\",\"filmy\",\"wiper\",\"chess\",\"lousy\",\"sails\",\"brahe\",\"ounce\",\"flits\",\"hindu\",\"manly\",\"beaux\",\"mimed\",\"liken\",\"forts\",\"jambs\",\"peeps\",\"lelia\",\"brews\",\"handy\",\"lusty\",\"brads\",\"marne\",\"pesos\",\"earle\",\"arson\",\"scout\",\"showy\",\"chile\",\"sumps\",\"hiked\",\"crook\",\"herbs\",\"silks\",\"alamo\",\"mores\",\"dunce\",\"blaze\",\"stank\",\"haste\",\"howls\",\"trots\",\"creon\",\"lisle\",\"pause\",\"hates\",\"mulch\",\"mined\",\"moder\",\"devin\",\"types\",\"cindy\",\"beech\",\"tuned\",\"mowed\",\"pitts\",\"chaos\",\"colds\",\"bidet\",\"tines\",\"sighs\",\"slimy\",\"brain\",\"belle\",\"leery\",\"morse\",\"ruben\",\"prows\",\"frown\",\"disco\",\"regal\",\"oaken\",\"sheds\",\"hives\",\"corny\",\"baser\",\"fated\",\"throe\",\"revel\",\"bores\",\"waved\",\"shits\",\"elvia\",\"ferns\",\"maids\",\"color\",\"coifs\",\"cohan\",\"draft\",\"hmong\",\"alton\",\"stine\",\"cluck\",\"nodes\",\"emily\",\"brave\",\\\n",
    "            \"blair\",\"blued\",\"dress\",\"bunts\",\"holst\",\"clogs\",\"rally\",\"knack\",\"demos\",\"brady\",\"blues\",\"flash\",\"goofy\",\"blocs\",\"diane\",\"colic\",\"smile\",\"yules\",\"foamy\",\"splay\",\"bilge\",\"faker\",\"foils\",\"condo\",\"knell\",\"crack\",\"gallo\",\"purls\",\"auras\",\"cakes\",\"doves\",\"joust\",\"aides\",\"lades\",\"muggy\",\"tanks\",\"middy\",\"tarps\",\"slack\",\"capet\",\"frays\",\"donny\",\"venal\",\"yeats\",\"misty\",\"denim\",\"glass\",\"nudes\",\"seeps\",\"gibbs\",\"blows\",\"bobbi\",\"shane\",\"yards\",\"pimps\",\"clued\",\"quiet\",\"witch\",\"boxes\",\"prawn\",\"kerry\",\"torah\",\"kinko\",\"dingy\",\"emote\",\"honor\",\"jelly\",\"grins\",\"trope\",\"vined\",\"bagel\",\"arden\",\"rapid\",\"paged\",\"loved\",\"agape\",\"mural\",\"budge\",\"ticks\",\"suers\",\"wendi\",\"slice\",\"salve\",\"robin\",\"bleat\",\"batik\",\"myles\",\"teddy\",\"flatt\",\"puppy\",\"gelid\",\"largo\",\"attar\",\"polls\",\"glide\",\"serum\",\"fundy\",\"sucks\",\"shalt\",\"sewer\",\"wreak\",\"dames\",\"fonts\",\"toxic\",\"hines\",\"wormy\",\"grass\",\"louse\",\"bowls\",\"crass\",\"benny\",\"moire\",\"margo\",\"golfs\",\"smart\",\"roxie\",\"wight\",\"reign\",\"dairy\",\"clops\",\"paled\",\"oddly\",\"sappy\",\"flair\",\"shown\",\"bulgy\",\"benet\",\"larch\",\"curry\",\"gulfs\",\"fends\",\"lunch\",\"dukes\",\"doris\",\"spoke\",\"coins\",\"manna\",\"conga\",\"jinns\",\"eases\",\"dunno\",\"tisha\",\"swore\",\"rhino\",\"calms\",\"irvin\",\"clans\",\"gully\",\"liege\",\"mains\",\"besot\",\"serge\",\"being\",\"welch\",\"wombs\",\"draco\",\"lynda\",\"forty\",\"mumps\",\"bloch\",\"ogden\",\"knits\",\"fussy\",\"alder\",\"danes\",\"loyal\",\"valet\",\"wooer\",\"quire\",\"liefs\",\"shana\",\"toyed\",\"forks\",\"gages\",\"slims\",\"cloys\",\"yates\",\"rails\",\"sheep\",\"nacho\",\"divan\",\"honks\",\"stone\",\"snack\",\"added\",\"basal\",\"hasps\",\"focus\",\"alone\",\"laxes\",\"arose\",\"lamed\",\"wrapt\",\"frail\",\"clams\",\"plait\",\"hover\",\"tacos\",\"mooch\",\"fault\",\"teeth\",\"marva\",\"mucks\",\"tread\",\"waves\",\"purim\",\"boron\",\"horde\",\"smack\",\"bongo\",\"monte\",\"swirl\",\"deals\",\"mikes\",\"scold\",\"muter\",\"sties\",\"lawns\",\"fluke\",\"jilts\",\"meuse\",\"fives\",\"sulky\",\"molds\",\"snore\",\"timmy\",\"ditty\",\"gasps\",\"kills\",\"carey\",\"jawed\",\"byers\",\"tommy\",\"homer\",\"hexed\",\"dumas\",\"given\",\"mewls\",\"smelt\",\"weird\",\"speck\",\"merck\",\"keats\",\"draws\",\"trent\",\"agave\",\"wells\",\"chews\",\"blabs\",\"roves\",\"grieg\",\"evens\",\"alive\",\"mulls\",\"cared\",\"garbo\",\"fined\",\"happy\",\"trued\",\"rodes\",\"thurs\",\"cadet\",\"alvin\",\"busch\",\"moths\",\"guild\",\"staci\",\"lever\",\"widen\",\"props\",\"hussy\",\"lamer\",\"riley\",\"bauer\",\"chirp\",\"rants\",\"poxes\",\"shyer\",\"pelts\",\"funny\",\"slits\",\"tinge\",\"ramos\",\"shift\",\"caper\",\"credo\",\"renal\",\"veils\",\"covey\",\"elmer\",\"mated\",\"tykes\",\"wooed\",\"briar\",\"gears\",\"foley\",\"shoes\",\"decry\",\"hypes\",\"dells\",\"wilds\",\"runts\",\"wilts\",\"white\",\"easts\",\"comer\",\"sammy\",\"lochs\",\"favor\",\"lance\",\"dawns\",\"bushy\",\"muted\",\"elsie\",\"creel\",\"pocks\",\"tenet\",\"cagey\",\"rides\",\"socks\",\"ogled\",\"soils\",\"sofas\",\"janna\",\"exile\",\"barks\",\"frank\",\"takes\",\"zooms\",\"hakes\",\"sagan\",\"scull\",\"heaps\",\"augur\",\"pouch\",\"blare\",\"bulbs\",\"wryly\",\"homey\",\"tubas\",\"limbo\",\"hardy\",\"hoagy\",\"minds\",\"bared\",\"gabby\",\"bilks\",\"float\",\"limns\",\"clasp\",\"laura\",\"range\",\"brush\",\"tummy\",\"kilts\",\"cooed\",\"worms\",\"leary\",\"feats\",\"robes\",\"suite\",\"veals\",\"bosch\",\"moans\",\"dozen\",\"rarer\",\"slyer\",\"cabin\",\"craze\",\"sweet\",\"talon\",\"treat\",\"yanks\",\"react\",\"creed\",\"eliza\",\"sluts\",\"cruet\",\"hafts\",\"noise\",\"seder\",\"flies\",\"weeks\",\"venus\",\"backs\",\"eider\",\"uriel\",\"vouch\",\"robed\",\"hacks\",\"perth\",\"shiny\",\"stilt\",\"torte\",\"throb\",\"merer\",\"twits\",\"reeds\",\"shawl\",\"clara\",\"slurs\",\"mixer\",\"newts\",\"fried\",\"woolf\",\"swoop\",\"kaaba\",\"oozed\",\"mayer\",\"caned\",\"laius\",\"lunge\",\"chits\",\"kenny\",\"lifts\",\"mafia\",\"sowed\",\"piled\",\"stein\",\"whack\",\"colts\",\"warms\",\"cleft\",\"girds\",\"seeks\",\"poets\",\"angel\",\"trade\",\"parsi\",\"tiers\",\"rojas\",\"vexes\",\"bryce\",\"moots\",\"grunt\",\"drain\",\"lumpy\",\"stabs\",\"poohs\",\"leapt\",\"polly\",\"cuffs\",\"giddy\",\"towns\",\"dacha\",\"quoth\",\"provo\",\"dilly\",\"carly\",\"mewed\",\"tzars\",\"crock\",\"toked\",\"speak\",\"mayas\",\"pssts\",\"ocher\",\"motel\",\"vogue\",\"camps\",\"tharp\",\"taunt\",\"drone\",\"taint\",\"badge\",\"scott\",\"scats\",\"bakes\",\"antes\",\"gruel\",\"snort\",\"capes\",\"plate\",\"folly\",\"adobe\",\"yours\",\"papaw\",\"hench\",\"moods\",\"clunk\",\"chevy\",\"tomas\",\"narcs\",\"vonda\",\"wiles\",\"prigs\",\"chock\",\"laser\",\"viced\",\"stiff\",\"rouse\",\"helps\",\"knead\",\"gazer\",\"blade\",\"tumid\",\"avail\",\"anger\",\"egged\",\"guide\",\"goads\",\"rabin\",\"toddy\",\"gulps\",\"flank\",\"brats\",\"pedal\",\"junky\",\"marco\",\"tinny\",\"tires\",\"flier\",\"satin\",\"darth\",\"paley\",\"gumbo\",\"rared\",\"muffs\",\"rower\",\"prude\",\"frees\",\"quays\",\"homes\",\"munch\",\"beefs\",\"leash\",\"aston\",\"colon\",\"finch\",\"bogey\",\"leaps\",\"tempo\",\"posts\",\"lined\",\"gapes\",\"locus\",\"maori\",\"nixes\",\"liven\",\"songs\",\"opted\",\"babel\",\"wader\",\"barer\",\"farts\",\"lisps\",\"koran\",\"lathe\",\"trill\",\"smirk\",\"mamma\",\"viler\",\"scurf\",\"ravel\",\"brigs\",\"cooky\",\"sachs\",\"fulls\",\"goals\",\"turfs\",\"norse\",\"hauls\",\"cores\",\"fairy\",\"pluto\",\"kneed\",\"cheek\",\"pangs\",\"risen\",\"czars\",\"milne\",\"cribs\",\"genes\",\"wefts\",\"vents\",\"sages\",\"seres\",\"owens\",\"wiley\",\"flume\",\"haded\",\"auger\",\"tatty\",\"onion\",\"cater\",\"wolfe\",\"magic\",\"bodes\",\"gulls\",\"gazes\",\"dandy\",\"snags\",\"rowed\",\"quell\",\"spurn\",\"shore\",\"veldt\",\"turns\",\"slavs\",\"coach\",\"stalk\",\"snuck\",\"piles\",\"orate\",\"joyed\",\"daily\",\"crone\",\"wager\",\"solos\",\"earns\",\"stark\",\"lauds\",\"kasey\",\"villa\",\"gnaws\",\"scent\",\"wears\",\"fains\",\"laced\",\"tamer\",\"pipes\",\"plant\",\"lorie\",\"rivet\",\"tamed\",\"cozen\",\"theme\",\"lifer\",\"sunny\",\"shags\",\"flack\",\"gassy\",\"eased\",\"jeeps\",\"shire\",\"fargo\",\"timer\",\"brash\",\"behan\",\"basin\",\"volga\",\"krone\",\"swiss\",\"docks\",\"booed\",\"ebert\",\"gusty\",\"delay\",\"oared\",\"grady\",\"buick\",\"curbs\",\"crete\",\"lucas\",\"strum\",\"besom\",\"gorse\",\"troth\",\"donne\",\"chink\",\"faced\",\"ahmed\",\"texas\",\"longs\",\"aloud\",\"bethe\",\"cacao\",\"hilda\",\"eagle\",\"karyn\",\"harks\",\"adder\",\"verse\",\"drays\",\"cello\",\"taped\",\"snide\",\"taxis\",\"kinky\",\"penes\",\"wicca\",\"sonja\",\"aways\",\"dyers\",\"bolas\",\"elfin\",\"slope\",\"lamps\",\"hutch\",\"lobed\",\"baaed\",\"masts\",\"ashes\",\"ionic\",\"joyce\",\"payed\",\"brays\",\"malts\",\"dregs\",\"leaky\",\"runny\",\"fecal\",\"woven\",\"hurls\",\"jorge\",\"henna\",\"dolby\",\"booty\",\"brett\",\"dykes\",\"rural\",\"fight\",\"feels\",\"flogs\",\"brunt\",\"preen\",\"elvis\",\"dopey\",\"gripe\",\"garry\",\"gamma\",\"fling\",\"space\",\"mange\",\"storm\",\"arron\",\"hairs\",\"rogue\",\"repel\",\"elgar\",\"ruddy\",\"cross\",\"medan\",\"loses\",\"howdy\",\"foams\",\"piker\",\"halts\",\"jewel\",\"avery\",\"stool\",\"cruel\",\"cases\",\"ruses\",\"cathy\",\"harem\",\"flour\",\"meted\",\"faces\",\"hobos\",\"charm\",\"jamar\",\"cameo\",\"crape\",\"hooey\",\"reefs\",\"denny\",\"mitts\",\"sores\",\"smoky\",\"nopes\",\"sooty\",\"twirl\",\"toads\",\"vader\",\"julep\",\"licks\",\"arias\",\"wrote\",\"north\",\"bunks\",\"heady\",\"batch\",\"snaps\",\"claws\",\"fouls\",\"faded\",\"beans\",\"wimps\",\"idled\",\"pulse\",\"goons\",\"noose\",\"vowed\",\"ronda\",\"rajas\",\"roast\",\"allah\",\"punic\",\"slows\",\"hours\",\"metal\",\"slier\",\"meaty\",\"hanna\",\"curvy\",\"mussy\",\"truth\",\"troys\",\"block\",\"reels\",\"print\",\"miffs\",\"busts\",\"bytes\",\"cream\",\"otter\",\"grads\",\"siren\",\"kilos\",\"dross\",\"batty\",\"debts\",\"sully\",\"bares\",\"baggy\",\"hippy\",\"berth\",\"gorky\",\"argon\",\"wacko\",\"harry\",\"smoke\",\"fails\",\"perms\",\"score\",\"steps\",\"unity\",\"couch\",\"kelly\",\"rumps\",\"fines\",\"mouth\",\"broth\",\"knows\",\"becky\",\"quits\",\"lauri\",\"trust\",\"grows\",\"logos\",\"apter\",\"burrs\",\"zincs\",\"buyer\",\"bayer\",\"moose\",\"overt\",\"croon\",\"ousts\",\"lands\",\"lithe\",\"poach\",\"jamel\",\"waive\",\"wiser\",\"surly\",\"works\",\"paine\",\"medal\",\"glads\",\"gybed\",\"paint\",\"lorre\",\"meant\",\"smugs\",\"bryon\",\"jinni\",\"sever\",\"viols\",\"flubs\",\"melts\",\"heads\",\"peals\",\"aiken\",\"named\",\"teary\",\"yalta\",\"styes\",\"heist\",\"bongs\",\"slops\",\"pouts\",\"grape\",\"belie\",\"cloak\",\"rocks\",\"scone\",\"lydia\",\"goofs\",\"rents\",\"drive\",\"crony\",\"orlon\",\"narks\",\"plays\",\"blips\",\"pence\",\"march\",\"alger\",\"baste\",\"acorn\",\"billy\",\"croce\",\"boone\",\"aaron\",\"slobs\",\"idyls\",\"irwin\",\"elves\",\"stoat\",\"doing\",\"globe\",\"verve\",\"icons\",\"trial\",\"olsen\",\"pecks\",\"there\",\"blame\",\"tilde\",\"milky\",\"sells\",\"tangy\",\"wrack\",\"fills\",\"lofty\",\"truce\",\"quark\",\"delia\",\"stowe\",\"marty\",\"overs\",\"putty\",\"coral\",\"swine\",\"stats\",\"swags\",\"weans\",\"spout\",\"bulky\",\"farsi\",\"brest\",\"gleam\",\"beaks\",\"coons\",\"hater\",\"peony\",\"huffy\",\"exert\",\"clips\",\"riven\",\"payer\",\"doped\",\"salas\",\"meyer\",\"dryad\",\"thuds\",\"tilts\",\"quilt\",\"jetty\",\"brood\",\"gulch\",\"corps\",\"tunic\",\"hubby\",\"slang\",\"wreck\",\"purrs\",\"punch\",\"drags\",\"chide\",\"sulks\",\"tints\",\"huger\",\"roped\",\"dopes\",\"booby\",\"rosin\",\"outer\",\"gusto\",\"tents\",\"elude\",\"brows\",\"lease\",\"ceres\",\"laxer\",\"worth\",\"necks\",\"races\",\"corey\",\"trait\",\"stuns\",\"soles\",\"teems\",\"scrip\",\"privy\",\"sight\",\"minor\",\"alisa\",\"stray\",\"spank\",\"cress\",\"nukes\",\"rises\",\"gusts\",\"aurae\",\"karma\",\"icing\",\"prose\",\"biked\",\"grand\",\"grasp\",\"skein\",\"shaky\",\"clump\",\"rummy\",\"stock\",\"twain\",\"zoned\",\"offed\",\"ghats\",\"mover\",\"randy\",\"vault\",\"craws\",\"thees\",\"salem\",\"downy\",\"sangs\",\"chore\",\"cited\",\"grave\",\"spinx\",\"erica\",\"raspy\",\"dying\",\"skips\",\"clerk\",\"paste\",\"moved\",\"rooks\",\"intel\",\"moses\",\"avers\",\"staid\",\"yawls\",\"blast\",\"lyres\",\"monks\",\"gaits\",\"floor\",\"saner\",\"waver\",\"assam\",\"infer\",\"wands\",\"bunch\",\"dryly\",\"weedy\",\"honey\",\"baths\",\"leach\",\"shorn\",\"shows\",\"dream\",\"value\",\"dooms\",\"spiro\",\"raped\",\"shook\",\"stead\",\"moran\",\"ditto\",\"loots\",\"tapir\",\"looms\",\"clove\",\"stops\",\"pinks\",\"soppy\",\"ripen\",\"wench\",\"shone\",\"bauds\",\"doric\",\"leans\",\"nadia\",\"cries\",\"camus\",\"boozy\",\"maris\",\"fools\",\"morns\",\"bides\",\"greek\",\"gauss\",\"roget\",\"lamar\",\"hazes\",\"beefy\",\"dupes\",\"refed\",\"felts\",\"larry\",\"guile\",\"ables\",\"wants\",\"warns\",\"toils\",\"bathe\",\"edger\",\"paced\",\"rinks\",\"shoos\",\"erich\",\"whore\",\"tiger\",\"jumpy\",\"lamas\",\"stack\",\"among\",\"punts\",\"scalp\",\"alloy\",\"solon\",\"quite\",\"comas\",\"whole\",\"parse\",\"tries\",\"reeve\",\"tiled\",\"deena\",\"roomy\",\"rodin\",\"aster\",\"twice\",\"musts\",\"globs\",\"parch\",\"drawn\",\"filch\",\"bonds\",\"tells\",\"droop\",\"janis\",\"holds\",\"scant\",\"lopes\",\"based\",\"keven\",\"whiny\",\"aspic\",\"gains\",\"franz\",\"jerri\",\"steel\",\"rowel\",\"vends\",\"yelps\",\"begin\",\"logic\",\"tress\",\"sunni\",\"going\",\"barge\",\"blood\",\"burns\",\"basks\",\"waifs\",\"bones\",\"skill\",\"hewer\",\"burly\",\"clime\",\"eking\",\"withs\",\"capek\",\"berta\",\"cheap\",\"films\",\"scoot\",\"tweed\",\"sizer\",\"wheat\",\"acton\",\"flung\",\"ponds\",\"tracy\",\"fiver\",\"berra\",\"roger\",\"mutes\",\"burke\",\"miked\",\"valve\",\"whisk\",\"runes\",\"parry\",\"toots\",\"japes\",\"roars\",\"rough\",\"irons\",\"romeo\",\"cages\",\"reeks\",\"cigar\",\"saiph\",\"dully\",\"hangs\",\"chops\",\"rolls\",\"prick\",\"acuff\",\"spent\",\"sulla\",\"train\",\"swell\",\"frets\",\"names\",\"anita\",\"crazy\",\"sixth\",\"blunt\",\"fewer\",\"large\",\\\n",
    "            \"brand\",\"slick\",\"spitz\",\"rears\",\"ogres\",\"toffy\",\"yolks\",\"flock\",\"gnawn\",\"eries\",\"blink\",\"skier\",\"feted\",\"tones\",\"snail\",\"ether\",\"barbs\",\"noses\",\"hears\",\"upset\",\"awash\",\"cloud\",\"trunk\",\"degas\",\"dungs\",\"rated\",\"shall\",\"yeahs\",\"coven\",\"sands\",\"susan\",\"fable\",\"gunny\",\"began\",\"serfs\",\"balls\",\"dinky\",\"madge\",\"prong\",\"spilt\",\"lilly\",\"brawn\",\"comet\",\"spins\",\"raids\",\"dries\",\"sorts\",\"makes\",\"mason\",\"mayra\",\"royce\",\"stout\",\"mealy\",\"pagan\",\"nasal\",\"folds\",\"libby\",\"coups\",\"photo\",\"mosey\",\"amens\",\"speed\",\"lords\",\"board\",\"fetal\",\"lagos\",\"scope\",\"raked\",\"bonus\",\"mutts\",\"willy\",\"sport\",\"bingo\",\"thant\",\"araby\",\"bette\",\"rebel\",\"gases\",\"small\",\"humus\",\"grosz\",\"beset\",\"slays\",\"steve\",\"scrap\",\"blahs\",\"south\",\"pride\",\"heels\",\"tubes\",\"beady\",\"lacey\",\"genus\",\"mauls\",\"vying\",\"spice\",\"sexes\",\"ester\",\"drams\",\"today\",\"comae\",\"under\",\"jests\",\"direr\",\"yoked\",\"tempi\",\"early\",\"boats\",\"jesus\",\"warts\",\"guppy\",\"gilda\",\"quota\",\"token\",\"edwin\",\"ringo\",\"gaped\",\"lemon\",\"hurst\",\"manor\",\"arrow\",\"mists\",\"prize\",\"silas\",\"blobs\",\"diets\",\"ervin\",\"stony\",\"buddy\",\"bates\",\"rabid\",\"ducat\",\"ewing\",\"jaunt\",\"beads\",\"doyen\",\"blush\",\"thoth\",\"tiles\",\"piper\",\"short\",\"peron\",\"alley\",\"decks\",\"shunt\",\"whirs\",\"cushy\",\"roils\",\"betty\",\"plugs\",\"woken\",\"jibes\",\"foray\",\"merak\",\"ruing\",\"becks\",\"whale\",\"shoot\",\"dwelt\",\"spawn\",\"fairs\",\"dozed\",\"celts\",\"blond\",\"tikes\",\"sabin\",\"feint\",\"vamps\",\"cokes\",\"willa\",\"slues\",\"bills\",\"force\",\"curst\",\"yokel\",\"surer\",\"miler\",\"fices\",\"arced\",\"douse\",\"hilly\",\"lucio\",\"tongs\",\"togas\",\"minty\",\"sagas\",\"pates\",\"welsh\",\"bruno\",\"decal\",\"elate\",\"linux\",\"gyros\",\"pryor\",\"mousy\",\"pains\",\"shake\",\"spica\",\"pupal\",\"probe\",\"mount\",\"shirk\",\"purus\",\"kilns\",\"rests\",\"graze\",\"hague\",\"spuds\",\"sweep\",\"momma\",\"burch\",\"maces\",\"samar\",\"brace\",\"riser\",\"booms\",\"build\",\"camel\",\"flyer\",\"synge\",\"sauna\",\"tonga\",\"tings\",\"promo\",\"hides\",\"clair\",\"elisa\",\"bower\",\"reins\",\"diann\",\"lubed\",\"nulls\",\"picks\",\"laban\",\"milch\",\"buber\",\"stomp\",\"bosom\",\"lying\",\"haled\",\"avert\",\"wries\",\"macon\",\"skids\",\"fumed\",\"ogles\",\"clods\",\"antic\",\"nosey\",\"crimp\",\"purge\",\"mommy\",\"cased\",\"taxes\",\"covet\",\"clack\",\"butch\",\"panty\",\"lents\",\"machs\",\"exude\",\"tooth\",\"adore\",\"shuck\",\"asses\",\"after\",\"terra\",\"dices\",\"aryan\",\"regor\",\"romes\",\"stile\",\"cairo\",\"maura\",\"flail\",\"eaves\",\"estes\",\"sousa\",\"visas\",\"baron\",\"civet\",\"kitty\",\"freed\",\"ralph\",\"tango\",\"gawks\",\"cheat\",\"study\",\"fancy\",\"fiber\",\"musks\",\"souse\",\"brims\",\"claim\",\"bikes\",\"venue\",\"sired\",\"thymi\",\"rivas\",\"skimp\",\"pleas\",\"woman\",\"gimpy\",\"cawed\",\"minos\",\"pints\",\"knock\",\"poked\",\"bowen\",\"risky\",\"towel\",\"oinks\",\"linus\",\"heals\",\"pears\",\"codas\",\"inner\",\"pitch\",\"harpy\",\"niger\",\"madly\",\"bumpy\",\"stair\",\"files\",\"nobel\",\"celli\",\"spars\",\"jades\",\"balmy\",\"kooky\",\"plums\",\"trues\",\"gloss\",\"trims\",\"daunt\",\"tubby\",\"dared\",\"wadis\",\"smell\",\"darby\",\"stink\",\"drill\",\"dover\",\"ruler\",\"laden\",\"dikes\",\"layla\",\"fells\",\"maker\",\"joked\",\"horns\",\"these\",\"baize\",\"spahn\",\"whens\",\"edged\",\"mushy\",\"plume\",\"tucks\",\"spurs\",\"husky\",\"dried\",\"bigot\",\"pupas\",\"drily\",\"aware\",\"hagar\",\"newly\",\"knots\",\"pratt\",\"feces\",\"sabik\",\"watts\",\"cooke\",\"riles\",\"seamy\",\"fleas\",\"dusts\",\"barfs\",\"roans\",\"pawns\",\"vivid\",\"kirks\",\"tania\",\"feral\",\"tubae\",\"horne\",\"aries\",\"brits\",\"combs\",\"chunk\",\"stork\",\"waned\",\"texan\",\"elide\",\"glens\",\"emery\",\"autos\",\"trams\",\"dosed\",\"cheri\",\"baits\",\"jacks\",\"whose\",\"fazed\",\"matte\",\"swans\",\"maxed\",\"write\",\"spays\",\"orion\",\"traci\",\"horse\",\"stars\",\"strut\",\"goods\",\"verge\",\"scuff\",\"award\",\"dives\",\"wires\",\"burnt\",\"dimly\",\"sleds\",\"mayan\",\"biped\",\"quirk\",\"sofia\",\"slabs\",\"waste\",\"robby\",\"mayor\",\"fatty\",\"items\",\"bowel\",\"mires\",\"swarm\",\"route\",\"swash\",\"sooth\",\"paved\",\"steak\",\"upend\",\"sough\",\"throw\",\"perts\",\"stave\",\"carry\",\"burgs\",\"hilts\",\"plane\",\"toady\",\"nadir\",\"stick\",\"foist\",\"gnarl\",\"spain\",\"enter\",\"sises\",\"story\",\"scarf\",\"ryder\",\"glums\",\"nappy\",\"sixes\",\"honed\",\"marcy\",\"offer\",\"kneel\",\"leeds\",\"lites\",\"voter\",\"vince\",\"bursa\",\"heave\",\"roses\",\"trees\",\"argos\",\"leann\",\"grimy\",\"zelma\",\"crick\",\"tract\",\"flips\",\"folks\",\"smote\",\"brier\",\"moore\",\"goose\",\"baden\",\"riled\",\"looks\",\"sober\",\"tusks\",\"house\",\"acmes\",\"lubes\",\"chows\",\"neath\",\"vivas\",\"defer\",\"allay\",\"casey\",\"kmart\",\"pests\",\"proms\",\"eying\",\"cider\",\"leave\",\"shush\",\"shots\",\"karla\",\"scorn\",\"gifts\",\"sneer\",\"mercy\",\"copes\",\"faxed\",\"spurt\",\"monet\",\"awoke\",\"rocky\",\"share\",\"gores\",\"drawl\",\"tears\",\"mooed\",\"nones\",\"wined\",\"wrens\",\"modem\",\"beria\",\"hovel\",\"retch\",\"mates\",\"hands\",\"stymy\",\"peace\",\"carat\",\"coots\",\"hotel\",\"karen\",\"hayed\",\"mamet\",\"cuing\",\"paper\",\"rages\",\"suave\",\"reuse\",\"auden\",\"costs\",\"loner\",\"rapes\",\"hazel\",\"rites\",\"brent\",\"pumps\",\"dutch\",\"puffs\",\"noons\",\"grams\",\"teats\",\"cease\",\"honda\",\"pricy\",\"forgo\",\"fleck\",\"hired\",\"silos\",\"merge\",\"rafts\",\"halon\",\"larks\",\"deere\",\"jello\",\"cunts\",\"sifts\",\"boner\",\"morin\",\"mimes\",\"bungs\",\"marie\",\"harts\",\"snobs\",\"sonic\",\"hippo\",\"comes\",\"crops\",\"mango\",\"wrung\",\"garbs\",\"natty\",\"cents\",\"fitch\",\"moldy\",\"adams\",\"sorta\",\"coeds\",\"gilds\",\"kiddy\",\"nervy\",\"slurp\",\"ramon\",\"fuzed\",\"hiker\",\"winks\",\"vanes\",\"goody\",\"hawks\",\"crowd\",\"bract\",\"marla\",\"limbs\",\"solve\",\"gloom\",\"sloop\",\"eaton\",\"memos\",\"tames\",\"heirs\",\"berms\",\"wanes\",\"faint\",\"numbs\",\"holes\",\"grubs\",\"rakes\",\"waist\",\"miser\",\"stays\",\"antis\",\"marsh\",\"skyed\",\"payne\",\"champ\",\"jimmy\",\"clues\",\"fatal\",\"shoed\",\"freon\",\"lopez\",\"snowy\",\"loins\",\"stale\",\"thank\",\"reads\",\"isles\",\"grill\",\"align\",\"saxes\",\"rubin\",\"rigel\",\"walls\",\"beers\",\"wispy\",\"topic\",\"alden\",\"anton\",\"ducts\",\"david\",\"duets\",\"fries\",\"oiled\",\"waken\",\"allot\",\"swats\",\"woozy\",\"tuxes\",\"inter\",\"dunne\",\"known\",\"axles\",\"graph\",\"bumps\",\"jerry\",\"hitch\",\"crews\",\"lucia\",\"banal\",\"grope\",\"valid\",\"meres\",\"thick\",\"lofts\",\"chaff\",\"taker\",\"glues\",\"snubs\",\"trawl\",\"keels\",\"liker\",\"stand\",\"harps\",\"casks\",\"nelly\",\"debby\",\"panes\",\"dumps\",\"norma\",\"racks\",\"scams\",\"forte\",\"dwell\",\"dudes\",\"hypos\",\"sissy\",\"swamp\",\"faust\",\"slake\",\"maven\",\"lowed\",\"lilts\",\"bobby\",\"gorey\",\"swear\",\"nests\",\"marci\",\"palsy\",\"siege\",\"oozes\",\"rates\",\"stunt\",\"herod\",\"wilma\",\"other\",\"girts\",\"conic\",\"goner\",\"peppy\",\"class\",\"sized\",\"games\",\"snell\",\"newsy\",\"amend\",\"solis\",\"duane\",\"troop\",\"linda\",\"tails\",\"woofs\",\"scuds\",\"shies\",\"patti\",\"stunk\",\"acres\",\"tevet\",\"allen\",\"carpi\",\"meets\",\"trend\",\"salty\",\"galls\",\"crept\",\"toner\",\"panda\",\"cohen\",\"chase\",\"james\",\"bravo\",\"styed\",\"coals\",\"oates\",\"swami\",\"staph\",\"frisk\",\"cares\",\"cords\",\"stems\",\"razed\",\"since\",\"mopes\",\"rices\",\"junes\",\"raged\",\"liter\",\"manes\",\"rearm\",\"naive\",\"tyree\",\"medic\",\"laded\",\"pearl\",\"inset\",\"graft\",\"chair\",\"votes\",\"saver\",\"cains\",\"knobs\",\"gamay\",\"hunch\",\"crags\",\"olson\",\"teams\",\"surge\",\"wests\",\"boney\",\"limos\",\"ploys\",\"algae\",\"gaols\",\"caked\",\"molts\",\"glops\",\"tarot\",\"wheal\",\"cysts\",\"husks\",\"vaunt\",\"beaus\",\"fauns\",\"jeers\",\"mitty\",\"stuff\",\"shape\",\"sears\",\"buffy\",\"maced\",\"fazes\",\"vegas\",\"stamp\",\"borer\",\"gaged\",\"shade\",\"finds\",\"frock\",\"plods\",\"skied\",\"stump\",\"ripes\",\"chick\",\"cones\",\"fixed\",\"coled\",\"rodeo\",\"basil\",\"dazes\",\"sting\",\"surfs\",\"mindy\",\"creak\",\"swung\",\"cadge\",\"franc\",\"seven\",\"sices\",\"weest\",\"unite\",\"codex\",\"trick\",\"fusty\",\"plaid\",\"hills\",\"truck\",\"spiel\",\"sleek\",\"anons\",\"pupae\",\"chiba\",\"hoops\",\"trash\",\"noted\",\"boris\",\"dough\",\"shirt\",\"cowls\",\"seine\",\"spool\",\"miens\",\"yummy\",\"grade\",\"proxy\",\"hopes\",\"girth\",\"deter\",\"dowry\",\"aorta\",\"paean\",\"corms\",\"giant\",\"shank\",\"where\",\"means\",\"years\",\"vegan\",\"derek\",\"tales\"]\n",
    "\n",
    "ladderLength(beginWord = \"nanny\",endWord = \"aloud\",wordList = wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit [['hit']]\n",
      "hot [['hit', 'hot']]\n",
      "dot [['hit', 'hot', 'dot']]\n",
      "lot [['hit', 'hot', 'lot']]\n",
      "dog [['hit', 'hot', 'dot', 'dog']]\n",
      "log [['hit', 'hot', 'lot', 'log']]\n",
      "cog [['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 126. Word Ladder II\n",
    "import collections\n",
    "def findLadders(beginWord, endWord, wordList):\n",
    "    \"\"\"\n",
    "    :type beginWord: str\n",
    "    :type endWord: str\n",
    "    :type wordList: List[str]\n",
    "    :rtype: List[List[str]]\n",
    "    \"\"\"\n",
    "    wordList = set(wordList)\n",
    "    queue = [[beginWord]]\n",
    "    while queue:\n",
    "        newqueue = []\n",
    "        for words in queue:\n",
    "            word = words[-1]\n",
    "            if word == endWord:\n",
    "                break\n",
    "            for i in range(len(word)):\n",
    "                for ch in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                    next_word = word[:i] + ch + word[i+1:]\n",
    "                    if next_word in wordList:\n",
    "                        temp = words +[next_word]\n",
    "                        newqueue += [temp]\n",
    "        for i in newqueue:\n",
    "            if i[-1] in wordList:\n",
    "                wordList.remove(i[-1])\n",
    "        if word == endWord:\n",
    "            break\n",
    "        queue = newqueue                   \n",
    "    return [i for i in queue if i[-1]==endWord]\n",
    "\n",
    "def findLadders(beginWord, endWord, wordList):\n",
    "    wordList = set(wordList)\n",
    "    res = []\n",
    "    layer = {}\n",
    "    layer[beginWord] = [[beginWord]]\n",
    "\n",
    "    while layer:\n",
    "        newlayer = collections.defaultdict(list)\n",
    "        for w in layer:\n",
    "            print(w,layer[w])\n",
    "            if w == endWord: \n",
    "                res.extend(k for k in layer[w])\n",
    "            else:\n",
    "                for i in range(len(w)):\n",
    "                    for c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        neww = w[:i]+c+w[i+1:]\n",
    "                        if neww in wordList:\n",
    "                            newlayer[neww]+=[j+[neww] for j in layer[w]]\n",
    "\n",
    "        wordList -= set(newlayer.keys())\n",
    "        layer = newlayer\n",
    "\n",
    "    return res\n",
    "findLadders(beginWord = \"hit\",endWord = \"cog\",wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"])\n",
    "# findLadders(beginWord = \"nanny\",endWord = \"aloud\",wordList = wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 417. Pacific Atlantic Water Flow\n",
    "def pacificAtlantic(matrix):\n",
    "    \"\"\"\n",
    "    :type matrix: List[List[int]]\n",
    "    :rtype: List[List[int]]\n",
    "    \"\"\"\n",
    "    direction = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    if not matrix or not matrix[0]:\n",
    "        return []\n",
    "    m,n = len(matrix),len(matrix[0])\n",
    "    pacific = [[False for _ in range(n)] for _ in range(m)]\n",
    "    atlantic = [[False for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "    queue =[[i,j] for i in range(m) for j in range(n) if i==0 or j==0]\n",
    "    while queue:\n",
    "        [x,y]=queue.pop(0)\n",
    "        pacific[x][y]=True\n",
    "        for xadd,yadd in direction:\n",
    "            xnew,ynew =x+xadd,y+yadd\n",
    "            if xnew<0 or xnew>=m or ynew<0 or ynew>=n or matrix[x][y]>matrix[xnew][ynew] or pacific[xnew][ynew]:\n",
    "                continue\n",
    "            pacific[xnew][ynew]=True\n",
    "            queue.append([xnew,ynew])\n",
    "    queue =[[i,j] for i in range(m) for j in range(n) if i==m-1 or j==n-1]\n",
    "    while queue:\n",
    "        [x,y]=queue.pop(0)\n",
    "        atlantic[x][y]=True\n",
    "        for xadd,yadd in direction:\n",
    "            xnew,ynew =x+xadd,y+yadd\n",
    "            if xnew<0 or xnew>=m or ynew<0 or ynew>=n or matrix[x][y]>matrix[xnew][ynew] or atlantic[xnew][ynew]:\n",
    "                continue\n",
    "            atlantic[xnew][ynew]=True\n",
    "            queue.append([xnew,ynew])\n",
    "    return [[i,j] for i in range(m) for j in range(n) if pacific[i][j] and atlantic[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[True, True, True, True, True], [True, True, True, True, True], [True, True, True, False, False], [True, True, False, False, False], [True, False, False, False, False]] [[False, False, False, False, True], [False, False, False, True, True], [False, False, True, True, True], [True, True, True, True, True], [True, True, True, True, True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 4], [1, 3], [1, 4], [2, 2], [3, 0], [3, 1], [4, 0]]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pacificAtlantic([[1,2,2,3,5],[3,2,3,4,4],[2,4,5,3,1],[6,7,1,4,5],[5,1,1,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Solution(object):\n",
    "    def pacificAtlantic(self, matrix):\n",
    "        \"\"\"\n",
    "        :type matrix: List[List[int]]\n",
    "        :rtype: List[List[int]]\n",
    "        \"\"\"\n",
    "        if not matrix: return []\n",
    "        self.directions = [(1,0),(-1,0),(0,1),(0,-1)]\n",
    "        m = len(matrix)\n",
    "        n = len(matrix[0])\n",
    "        p_visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "        \n",
    "        a_visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "        result = []\n",
    "        \n",
    "        for i in range(m):\n",
    "            # p_visited[i][0] = True\n",
    "            # a_visited[i][n-1] = True\n",
    "            self.dfs(matrix, i, 0, p_visited, m, n)\n",
    "            self.dfs(matrix, i, n-1, a_visited, m, n)\n",
    "        for j in range(n):\n",
    "            # p_visited[0][j] = True\n",
    "            # a_visited[m-1][j] = True\n",
    "            self.dfs(matrix, 0, j, p_visited, m, n)\n",
    "            self.dfs(matrix, m-1, j, a_visited, m, n)\n",
    "            \n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if p_visited[i][j] and a_visited[i][j]:\n",
    "                    result.append([i,j])\n",
    "        return result\n",
    "                \n",
    "                \n",
    "    def dfs(self, matrix, i, j, visited, m, n):\n",
    "        # when dfs called, meaning its caller already verified this point \n",
    "        visited[i][j] = True\n",
    "        for dir in self.directions:\n",
    "            x, y = i + dir[0], j + dir[1]\n",
    "            if x < 0 or x >= m or y < 0 or y >= n or visited[x][y] or matrix[x][y] < matrix[i][j]:\n",
    "                continue\n",
    "            self.dfs(matrix, x, y, visited, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 787. Cheapest Flights Within K Stops\n",
    "# 我的答案是错的，暂时不知道错误原因，用DP做很快\n",
    "def findCheapestPrice(n, flights, src, dst, K):\n",
    "    nodes = [i for i in range(n)]\n",
    "    adj = {i: dict() for i in nodes}\n",
    "    for i in flights:\n",
    "        adj[i[0]][i[1]]=i[2]\n",
    "    dis = {i: adj[src].setdefault(i,float('inf')) for i in nodes if i!=src}\n",
    "    visited = set()\n",
    "    \n",
    "    for i in range(K):\n",
    "        des = [i for i in dis.keys() if dis[i]<float('inf')]\n",
    "        temp = {}\n",
    "        for n in des:\n",
    "            if n!=dst and n not in visited:\n",
    "                visited.add(n)\n",
    "                for m in adj[n].keys():\n",
    "                    if m!=src and dis[n]+adj[n][m]<dis[m]:\n",
    "                        temp[m]=dis[n]+adj[n][m]\n",
    "        for m in temp.keys():\n",
    "            dis[m]=temp[m]\n",
    "    return dis[dst] if dis[dst]!=float('inf') else -1\n",
    "\n",
    "def findCheapestPrice(n, flights, src, dst, K):\n",
    "    prices = [float('inf') for i in range(n)]\n",
    "    prices[src]=0\n",
    "    \n",
    "    for i in range(K+1):\n",
    "        newprices = prices[:]\n",
    "        for a,b,cost in flights:\n",
    "            newprices[b] = min(newprices[b],prices[a]+cost)\n",
    "        prices = newprices\n",
    "    \n",
    "    return prices[dst] if prices[dst]!=float('inf') else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "695. Max Area of Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 695. Max Area of Island\n",
    "# DFS利用迭代，边界条件\n",
    "def maxAreaOfIsland(grid):\n",
    "    \"\"\"\n",
    "    :type grid: List[List[int]]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    if not grid or not grid[0]:\n",
    "        return 0\n",
    "    directions = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    m,n = len(grid),len(grid[0])\n",
    "    visited = [[False for _ in range(n)] for _ in range(m)]\n",
    "    \n",
    "    def find_next(i,j):\n",
    "        for col in range(j,n):\n",
    "            if grid[i][col] and not visited[i][col]:\n",
    "                return i,col\n",
    "        for row in range(i,m):\n",
    "            for col in range(n):\n",
    "                if grid[row][col] and not visited[row][col]:\n",
    "                    return row,col\n",
    "        return -1,-1\n",
    "    \n",
    "    i,j=find_next(0,0)\n",
    "    if i==-1:\n",
    "        return 0\n",
    "    queue = [(i,j)]\n",
    "    length = 0\n",
    "    res = 0\n",
    "    while queue:\n",
    "        x,y=queue.pop(0)\n",
    "        visited[x][y]=True\n",
    "        length +=1\n",
    "        for direction in directions:\n",
    "            xnew = x+direction[0]\n",
    "            ynew = y+direction[1]\n",
    "            if 0<=xnew<m and 0<=ynew<n and grid[xnew][ynew] and visited[xnew][ynew] is False:\n",
    "                queue.append((xnew,ynew))\n",
    "                visited[xnew][ynew]=True\n",
    "        if len(queue)==0:\n",
    "            res = max(res,length)\n",
    "            i,j = find_next(x,y)\n",
    "            length = 0\n",
    "            if i!=-1:\n",
    "                queue = [(i,j)]\n",
    "    return res\n",
    "\n",
    "def maxAreaOfIsland(grid):\n",
    "    m, n = len(grid), len(grid[0])\n",
    "\n",
    "    def dfs(i, j):\n",
    "        if 0 <= i < m and 0 <= j < n and grid[i][j]:\n",
    "            grid[i][j] = 0\n",
    "            return 1 + dfs(i - 1, j) + dfs(i, j + 1) + dfs(i + 1, j) + dfs(i, j - 1)\n",
    "        return 0\n",
    "\n",
    "    areas = [dfs(i, j) for i in range(m) for j in range(n) if grid[i][j]]\n",
    "    return max(areas) if areas else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxAreaOfIsland([[0,0,1,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 576. Out of Boundary Paths\n",
    "def findPaths(m, n, N, i, j):\n",
    "    \"\"\"\n",
    "    :type m: int\n",
    "    :type n: int\n",
    "    :type N: int\n",
    "    :type i: int\n",
    "    :type j: int\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    directions = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    ans = 0\n",
    "    def dfs(x,y,counts,N):\n",
    "        if N==0:\n",
    "            return counts\n",
    "        for direction in directions:\n",
    "            xnew,ynew=x+direction[0],y+direction[1]\n",
    "            if xnew==-1 or xnew==m or ynew==-1 or ynew==n:\n",
    "                counts +=1\n",
    "            else:\n",
    "                counts += dfs(xnew,ynew,0,N-1)\n",
    "        return counts%(10**9 + 7)\n",
    "\n",
    "    return dfs(i,j,ans,N)\n",
    "\n",
    "def findPaths(m,n,N,i,j):\n",
    "    mod = 10**9 + 7\n",
    "    Q = collections.deque([(i,j,0)])\n",
    "    res = 0\n",
    "    while Q:\n",
    "        x,y,step = Q.popleft()\n",
    "        if step > N: break\n",
    "        if 0<=x<m and 0<=y<n:\n",
    "            Q.append((x+1,y,step+1))\n",
    "            Q.append((x-1,y,step+1))\n",
    "            Q.append((x,y+1,step+1))\n",
    "            Q.append((x,y-1,step+1))\n",
    "        else:\n",
    "            res += 1\n",
    "    return res % mod\n",
    "\n",
    "findPaths(m = 10, n =12, N = 30, i = 5, j = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 79. Word Search\n",
    "# 二维矩阵中存在特定的词汇（路径）\n",
    "def exist(board, word):\n",
    "    if not board:\n",
    "        return False\n",
    "    directions = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "    m,n = len(board),len(board[0])\n",
    "    def dfs(i,j,k,visited=set()):\n",
    "        if k==len(word)-1:\n",
    "            return True\n",
    "        k=k+1\n",
    "        temp = False\n",
    "        for direction in directions:\n",
    "            x,y = i+direction[0],j+direction[1]\n",
    "            if 0<=x<m and 0<=y<n:\n",
    "                if (x,y) not in visited and board[x][y]==word[k]:\n",
    "                    if dfs(x,y,k,visited|{(i,j)}):\n",
    "                        return True\n",
    "#                     temp =temp|dfs(x,y,k,visited)\n",
    "#                     if temp:\n",
    "#                         visited.add((i,j))\n",
    "#                         return True\n",
    "        return False\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if board[i][j]==word[0]:\n",
    "                if dfs(i,j,k=0,visited=set()):\n",
    "                    return True\n",
    "    return False\n",
    "exist([['A','B','C','E'],['S','F','C','S'],['A','D','E','E']],'ABCESCEE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [4, 5, 1, 7, 1, 4]\n",
      "i 0 4\n",
      "2 [5, 1, 7, 1, 4] False\n",
      "-3 [1, 7, 1, 4] False\n",
      "i 1 5\n",
      "1 [1, 7, 1, 4] True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 416. Partition Equal Subset Sum\n",
    "def canPartition(nums):\n",
    "    \"\"\"\n",
    "    :type nums: List[int]\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    def exist(d,nums):#nums中是否能凑出这个数\n",
    "        print(d,nums,d in nums)\n",
    "        if d in nums or d==0:\n",
    "            return True\n",
    "        elif (d!=0 and len(nums)==0) or d<min(nums):\n",
    "            return False\n",
    "        else:\n",
    "            ans=exist(d-nums[0],nums[1:])\n",
    "            if ans is True:\n",
    "                return True\n",
    "            \n",
    "    if sum(nums)%2==1 or max(nums)>sum(nums)/2:\n",
    "        return False\n",
    "    diff=sum(nums)//2-max(nums)#需要补的数\n",
    "    nums.remove(max(nums))\n",
    "    if diff==0:#补的数为0\n",
    "        return True\n",
    "    print(diff,nums)\n",
    "    for i in range(len(nums)):#一个个元素判断，是否需要其构成那个差值,如果实在找不到，跳过\n",
    "        print('i',i,nums[i])\n",
    "        if exist(diff-nums[i],nums[i+1:]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# def canPartition(nums):#非常慢\n",
    "#     possible_sums = {0}\n",
    "#     for n in nums:\n",
    "#         possible_sums.update({(v + n) for v in possible_sums})\n",
    "#         print(possible_sums)\n",
    "#     return (sum(nums) / 2.)  in possible_sums \n",
    "canPartition([ 4,5,1, 10,7,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 419. Battleships in a Board,二维数组里横和直的个数\n",
    "def countBattleships(board):\n",
    "    if len(board) == 0: return 0\n",
    "    m, n = len(board), len(board[0])\n",
    "    count = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if board[i][j] == 'X' and (i == 0 or board[i-1][j] == '.') and (j == 0 or board[i][j-1] == '.'):\n",
    "                count += 1\n",
    "    return count\n",
    "countBattleships(\n",
    "[[\"X\",\".\",\".\",\"X\"],[\".\",\".\",\".\",\"X\"],[\".\",\".\",\".\",\"X\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "错的\n",
    "# def addOperators(num, target):\n",
    "#     \"\"\"\n",
    "#     :type num: str\n",
    "#     :type target: int\n",
    "#     :rtype: List[str]\n",
    "#     \"\"\"\n",
    "#     ans = []\n",
    "\n",
    "#     def operator(cur,index,path,temp,flag,num,target,ans):\n",
    "#         if index ==len(num):\n",
    "#             if sum(cur) == target:\n",
    "#                 print(cur,path,target)\n",
    "#                 ans.append(path)\n",
    "#             return\n",
    "#         elif cur==[]:\n",
    "#             operator([int(num[index])],index+1,path+num[index],temp,flag,num,target,ans)\n",
    "#         else:\n",
    "#             print(cur)\n",
    "#             if cur[-1]!=0 and flag2:\n",
    "#                 operator(cur[:-1]+[10*cur[-1]+int(num[index])],index+1,path+num[index],temp,flag,num,target,ans)\n",
    "#             operator(cur[:-1]+[cur[-1]*int(num[index])],index+1,path+'*'+num[index],num[index],0,num,target,ans)\n",
    "# #             if flag:\n",
    "# #                 operator(cur[:-1]+[cur[-1]//int(temp)*(int(temp)*10+int(num[index]))],index+1,path+num[index],str((int(temp)*10+int(num[index]))),1,num,target,ans)\n",
    "# #                 operator(cur[:-1]+[cur[-1]//int(temp)*(int(temp)*10+int(num[index]))],index+1,path+num[index],str((int(temp)*10+int(num[index]))),0,num,target,ans)\n",
    "#             operator(cur+[int(num[index])],index+1,path+'+'+num[index],temp,flag,num,target,ans)\n",
    "#             operator(cur+[-int(num[index])],index+1,path+'-'+num[index],temp,flag,num,target,ans)\n",
    "#         return\n",
    "\n",
    "#     operator([],0,\"\",\"\",0,num,target,ans)\n",
    "    \n",
    "#     return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 473. Matchsticks to Square,是否可以平分为4等份\n",
    "\n",
    "\n",
    "def makesquare(nums):\n",
    "    \"\"\"\n",
    "    :type nums: List[int]\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    if not nums:\n",
    "        return False\n",
    "    sums = sum(nums)\n",
    "    if sums%4!=0:\n",
    "        return False\n",
    "    nums.sort(reverse=True)\n",
    "    target = sums//4\n",
    "    def dfs(idx,cursum):\n",
    "        if idx==len(nums) and cursum == [target,target,target,target]:\n",
    "            return True\n",
    "        if idx==len(nums):\n",
    "            return False\n",
    "        temp = False\n",
    "        for i in range(4):\n",
    "            if cursum[i]+nums[idx]<=target:\n",
    "                cursum[i]+=nums[idx]\n",
    "                temp = temp | dfs(idx+1,cursum)\n",
    "                cursum[i]-=nums[idx]\n",
    "            if temp:\n",
    "                return True\n",
    "        return temp\n",
    "\n",
    "    return dfs(0,[0,0,0,0])\n",
    "\n",
    "makesquare([1,1,2,2,2])\n",
    "\n",
    "\n",
    "# 698. Partition to K Equal Sum Subsets\n",
    "# The key is, cursum[i] == 0 means for all k > i, cursum[k] == 0\n",
    "# because this algorithm always fill the previous buckets before trying the next.\n",
    "def canPartitionKSubsets(nums, k):\n",
    "    \"\"\"\n",
    "    :type nums: List[int]\n",
    "    :type k: int\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    if not nums:\n",
    "        return False\n",
    "    sums = sum(nums)\n",
    "    if sums%k!=0:\n",
    "        return False\n",
    "    nums.sort(reverse=True)\n",
    "    target = sums//k\n",
    "    def dfs(idx,cursum):\n",
    "#         print(cursum)\n",
    "        if idx==len(nums) and cursum == [target for _ in range(k)]:\n",
    "            return True\n",
    "        if idx==len(nums):\n",
    "            return False\n",
    "        temp = False\n",
    "        for i in range(k):\n",
    "            if cursum[i]+nums[idx]<=target:\n",
    "                cursum[i]+=nums[idx]\n",
    "                temp = temp | dfs(idx+1,cursum)\n",
    "                cursum[i]-=nums[idx]\n",
    "            if temp:\n",
    "                return True\n",
    "            if cursum[i]==0:#这一步很重要，如果没有，会慢很多\n",
    "                break\n",
    "        return temp\n",
    "\n",
    "    return dfs(0,[0 for _ in range(k)])\n",
    "\n",
    "canPartitionKSubsets(nums = [4, 3, 2, 3, 5, 2, 1], k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1273. Delete Tree Nodes,删除和为0的子树\n",
    "import collections\n",
    "def deleteTreeNodes(nodes, parent, value):\n",
    "    \"\"\"\n",
    "    :type nodes: int\n",
    "    :type parent: List[int]\n",
    "    :type value: List[int]\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    parents = collections.defaultdict(list)#每个parents拥有的child\n",
    "    for i,node in enumerate(parent):\n",
    "        parents[node].append(i)\n",
    "\n",
    "    def calSum(node):#这个节点及子节点的和,这个节点及其以下还幸存的节点个数\n",
    "#         if len(parents[node])==0:\n",
    "#             if value[node]==0:\n",
    "#                 return (0,0)\n",
    "#             return (value[node],1)\n",
    "        cursum,curnodes = value[node],1\n",
    "        for i in parents[node]:\n",
    "            r1,r2 = calSum(i)\n",
    "            cursum+=r1\n",
    "            curnodes+=r2\n",
    "        return (cursum,curnodes) if cursum!=0 else (0,0)\n",
    "    return calSum(0)[1]\n",
    "deleteTreeNodes(nodes = 7, parent = [-1,0,0,1,2,2,2], value = [1,-2,4,0,-2,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 2, 5, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 851. Loud and Rich，给定树结构，求每个的比它小的节点\n",
    "# 从叶子出发，一层层推进，中途更新值\n",
    "def loudAndRich(richer, quiet):\n",
    "    \"\"\"\n",
    "    :type richer: List[List[int]]\n",
    "    :type quiet: List[int]\n",
    "    :rtype: List[int]\n",
    "    \"\"\"\n",
    "    # [1,2],1>2\n",
    "    large = {i:set() for i in range(len(quiet))}#每个元素与比他大的{2:1}\n",
    "    small = {i:set() for i in range(len(quiet))}#每个元素和比他小的{1:2}\n",
    "    for i,j in richer:\n",
    "        large[j].add(i)\n",
    "        small[i].add(j)\n",
    "\n",
    "    res = [i for i in range(len(quiet))]\n",
    "    visited = set()\n",
    "\n",
    "    while len(visited)<len(res):\n",
    "        nodes = [i for i in large if len(large[i])==0 and (i not in visited)]\n",
    "        for node in nodes:\n",
    "            visited.add(node)\n",
    "            for key in list(small[node]):\n",
    "                if quiet[res[node]]<quiet[res[key]]:\n",
    "                    res[key] = res[node]\n",
    "                large[key].remove(node)\n",
    "    return res\n",
    "loudAndRich(richer = [[1,0],[2,1],[3,1],[3,7],[4,3],[5,3],[6,3]], quiet = [3,2,5,4,6,1,7,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 756. Pyramid Transition Matrix\n",
    "# 为什么这里用的DFS而不是用BFS,BFS需要每次把每一轮的所有选项全部跑完\n",
    "# 但这里DFS第一轮跑完后，直接对每一个状态走下一轮，直到可能走完，一旦有正确的，就可以了\n",
    "import itertools\n",
    "def pyramidTransition( bottom, allowed):\n",
    "    \"\"\"\n",
    "    :type bottom: str\n",
    "    :type allowed: List[str]\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    allow = dict()\n",
    "    for node in allowed:\n",
    "        if node[:2] not in allow:\n",
    "            allow[node[:2]] = []\n",
    "        allow[node[:2]].append(node[-1])\n",
    "\n",
    "    def dfs(status):\n",
    "        if len(status)==1:\n",
    "            return True\n",
    "        nxts = []\n",
    "        for j in range(len(status)-1):\n",
    "            if status[j]+status[j+1] in allow:\n",
    "                nxts.append(allow[status[j]+status[j+1]])\n",
    "            else:#找不到下一个，必须返回False，否则会出现错误\n",
    "                return False\n",
    "        for key in itertools.product(*nxts):#星号可以在一个列表内对元素进行映射\n",
    "            if dfs(key):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    return dfs(bottom)\n",
    "pyramidTransition(bottom = \"BCD\", allowed = [\"BCG\", \"CDE\", \"GEA\", \"FFF\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
